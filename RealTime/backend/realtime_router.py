# å®æ—¶å¯¹è¯è·¯ç”± - FastAPI

from fastapi import APIRouter, Query, HTTPException
from fastapi.responses import StreamingResponse
from typing import Optional
import json

from .models import TTSRequest, WarmupRequest, SwitchRefAudioRequest, ChatStreamRequest
from .services import ConfigService, TTSService, WarmupService, get_llm_service
from .text_chunker import TextChunker

router = APIRouter(tags=["realtime"])

# æœåŠ¡å±‚ä¾èµ–æ³¨å…¥
_config = ConfigService()
_tts = TTSService(_config)
_warmup = WarmupService(_config)
_chunker = TextChunker(min_length=5, max_length=50)
_llm = get_llm_service()


# ===================== TTS æ ¸å¿ƒæ¥å£ =====================

@router.post("/tts_stream")
async def tts_stream(request: TTSRequest):
    """
    æµå¼ TTS ç”Ÿæˆ
    
    æ¥æ”¶æ–‡æœ¬ç‰‡æ®µï¼Œè¿”å›æµå¼éŸ³é¢‘
    
    Returns:
        audio/wav æµå¼å“åº”
    """
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    
    if not request.ref_audio_path:
        raise HTTPException(status_code=400, detail="å‚è€ƒéŸ³é¢‘è·¯å¾„ä¸èƒ½ä¸ºç©º")
    
    print(f"[RealtimeRouter] æ”¶åˆ°TTSè¯·æ±‚: '{request.text[:30]}...'")
    
    async def generate():
        async for chunk in _tts.stream_tts(
            text=request.text,
            ref_audio_path=request.ref_audio_path,
            prompt_text=request.prompt_text,
            text_lang=request.text_lang,
            prompt_lang=request.prompt_lang,
            is_first_chunk=request.is_first_chunk
        ):
            yield chunk
    
    return StreamingResponse(
        generate(),
        media_type="audio/wav",
        headers={
            "Cache-Control": "no-cache",
            "X-Content-Type-Options": "nosniff"
        }
    )


@router.post("/interrupt")
async def interrupt():
    """
    æ‰“æ–­å½“å‰å¯¹è¯
    
    å–æ¶ˆæ­£åœ¨è¿›è¡Œçš„ TTS è¯·æ±‚ï¼Œæ¸…ç©ºæ–‡æœ¬ç¼“å†²åŒº
    
    Returns:
        {success: bool, message: str}
    """
    # æ¸…ç©ºåˆ†æ®µå™¨ç¼“å†²åŒº
    _chunker.clear()
    
    # å–æ¶ˆ TTS è¯·æ±‚
    cancelled = _tts.cancel()
    
    print(f"[RealtimeRouter] æ‰“æ–­è¯·æ±‚: cancelled={cancelled}")
    
    return {
        "success": True,
        "message": "å·²æ‰“æ–­" if cancelled else "æ— è¿›è¡Œä¸­çš„è¯·æ±‚"
    }


@router.get("/ref_audio")
async def get_ref_audio(char_name: Optional[str] = Query(None)):
    """
    è·å–å‚è€ƒéŸ³é¢‘ä¿¡æ¯
    
    Args:
        char_name: è§’è‰²åç§° (å¯é€‰)
        
    Returns:
        {path, text, lang} å‚è€ƒéŸ³é¢‘ä¿¡æ¯
    """
    ref = _config.get_default_ref_audio(char_name)
    
    if not ref.get("path"):
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°å‚è€ƒéŸ³é¢‘é…ç½®")
    
    return ref


@router.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "service": "realtime",
        "sovits_host": _config.sovits_host
    }


# ===================== æµå¼å¯¹è¯æ¥å£ =====================

@router.post("/chat_stream")
async def chat_stream(request: ChatStreamRequest):
    """
    æµå¼å¯¹è¯ - åç«¯å¤„ç† LLM + TTS
    
    æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œè¿”å› SSE äº‹ä»¶æµï¼š
    - event: token - LLM ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
    - event: tts_start - TTS å¼€å§‹ç”Ÿæˆï¼ˆåŒ…å«åˆ†æ®µæ–‡æœ¬ï¼‰
    - event: done - å¯¹è¯å®Œæˆ
    
    Returns:
        text/event-stream SSE å“åº”
    """
    if not request.user_input.strip():
        raise HTTPException(status_code=400, detail="ç”¨æˆ·è¾“å…¥ä¸èƒ½ä¸ºç©º")
    
    print(f"[RealtimeRouter] ğŸ’¬ æ”¶åˆ°å¯¹è¯è¯·æ±‚: '{request.user_input[:50]}...'")
    
    async def generate_stream():
        """ç”Ÿæˆ SSE äº‹ä»¶æµ"""
        full_response = ""
        text_buffer = ""
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = request.messages or []
        if request.system_prompt:
            messages = [{"role": "system", "content": request.system_prompt}] + messages
        elif not any(m.get("role") == "system" for m in messages):
            messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„å¯¹è¯åŠ©æ‰‹ã€‚è¯·ä¿æŒå›å¤ç®€æ´ï¼Œé€‚åˆè¯­éŸ³æœ—è¯»ã€‚"}] + messages
        
        messages.append({"role": "user", "content": request.user_input})
        
        try:
            # æµå¼è°ƒç”¨ LLM
            async for token in _llm.call_stream(messages):
                full_response += token
                text_buffer += token
                
                # å‘é€ token äº‹ä»¶
                yield f"event: token\ndata: {json.dumps({'content': token}, ensure_ascii=False)}\n\n"
                
                # å°è¯•åˆ†æ®µ
                chunks = _chunker.feed(token)
                for chunk in chunks:
                    # å‘é€ TTS å¼€å§‹äº‹ä»¶
                    yield f"event: tts_start\ndata: {json.dumps({'text': chunk}, ensure_ascii=False)}\n\n"
            
            # åˆ·æ–°å‰©ä½™å†…å®¹
            remaining = _chunker.flush()
            if remaining:
                yield f"event: tts_start\ndata: {json.dumps({'text': remaining}, ensure_ascii=False)}\n\n"
            
            # å‘é€å®Œæˆäº‹ä»¶
            yield f"event: done\ndata: {json.dumps({'full_response': full_response}, ensure_ascii=False)}\n\n"
            
            print(f"[RealtimeRouter] âœ… å¯¹è¯å®Œæˆï¼Œé•¿åº¦: {len(full_response)}")
            
        except Exception as e:
            print(f"[RealtimeRouter] âŒ å¯¹è¯é”™è¯¯: {e}")
            yield f"event: error\ndata: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


# ===================== é¢„çƒ­ç›¸å…³æ¥å£ =====================

@router.post("/warmup")
async def warmup(request: WarmupRequest = None):
    """
    é¢„çƒ­ GPT-SoVITS æ¨¡å‹
    
    é€šè¿‡å‘é€ä¸€ä¸ªçŸ­æ–‡æœ¬è¯·æ±‚ï¼Œè®© GPT-SoVITS æå‰ç¼“å­˜å‚è€ƒéŸ³é¢‘ç‰¹å¾ã€‚
    é¢„çƒ­åï¼Œåç»­è¯·æ±‚çš„å»¶è¿Ÿå°†ä» ~3s é™è‡³ ~0.3sã€‚
    
    å¦‚æœä¸ä¼ å‚æ•°ï¼Œå°†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å‚è€ƒéŸ³é¢‘ã€‚
    
    Returns:
        {success, message, ref_audio_path, elapsed_ms, skipped}
    """
    if request is None:
        request = WarmupRequest()
    
    result = _warmup.warmup(
        ref_audio_path=request.ref_audio_path,
        prompt_text=request.prompt_text,
        prompt_lang=request.prompt_lang,
        force=request.force
    )
    
    return result


@router.post("/switch_ref_audio")
async def switch_ref_audio(request: SwitchRefAudioRequest):
    """
    åˆ‡æ¢å‚è€ƒéŸ³é¢‘ï¼ˆç”¨äºè§’è‰²åˆ‡æ¢ï¼‰
    
    åˆ‡æ¢åˆ°æ–°çš„å‚è€ƒéŸ³é¢‘ï¼Œå¹¶å¯é€‰æ‹©è‡ªåŠ¨é¢„çƒ­ã€‚
    
    Returns:
        {success, message, old_path, new_path, warmup_result}
    """
    result = _warmup.switch_ref_audio(
        ref_audio_path=request.ref_audio_path,
        prompt_text=request.prompt_text,
        prompt_lang=request.prompt_lang,
        auto_warmup=request.auto_warmup
    )
    
    return result


@router.get("/warmup_status")
async def warmup_status():
    """
    è·å–å½“å‰é¢„çƒ­çŠ¶æ€
    
    Returns:
        {is_warmed_up, ref_audio_path, prompt_text, prompt_lang}
    """
    return _warmup.get_warmup_status()


# ===================== ä¼šè¯ç®¡ç†æ¥å£ =====================

from .models import UpdateContextRequest, SwitchSceneRequest, BuildPromptRequest
from .session_manager import session_manager
from .prompt import SceneManager

@router.post("/session/update_context")
async def update_context(request: UpdateContextRequest):
    """
    æ›´æ–°ä¸Šä¸‹æ–‡ï¼ˆæ¥æ”¶é…’é¦†æ•°æ®ï¼‰
    
    æ”¯æŒä¸¤ç§æ–¹å¼:
    1. ä¼ å…¥å®Œæ•´çš„é…’é¦†ä¸Šä¸‹æ–‡ (context å­—æ®µ)
    2. åˆ†åˆ«ä¼ å…¥è§’è‰²å’Œæ¶ˆæ¯ (character, messages å­—æ®µ)
    
    Returns:
        {success, message, status}
    """
    data = {}
    
    # ä¼˜å…ˆä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡
    if request.context:
        data = request.context
    else:
        if request.character:
            data["character"] = request.character
        if request.messages:
            data["messages"] = request.messages
        if request.chat_id:
            data["chatId"] = request.chat_id
    
    if not data:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰æä¾›æœ‰æ•ˆæ•°æ®")
    
    success = session_manager.update_from_sillytavern(data)
    
    return {
        "success": success,
        "message": "ä¸Šä¸‹æ–‡å·²æ›´æ–°" if success else "æ›´æ–°å¤±è´¥",
        "status": session_manager.get_status()
    }


@router.post("/session/switch_scene")
async def switch_scene(request: SwitchSceneRequest):
    """
    åˆ‡æ¢åœºæ™¯
    
    Returns:
        {success, current_scene, available_scenes}
    """
    success = session_manager.switch_scene(request.scene_id)
    
    return {
        "success": success,
        "current_scene": session_manager.get_current_scene(),
        "available_scenes": SceneManager.list_scenes()
    }


@router.get("/session/scenes")
async def list_scenes():
    """
    è·å–æ‰€æœ‰å¯ç”¨åœºæ™¯
    
    Returns:
        {scenes: [{id, name}, ...], current: {id, name}}
    """
    return {
        "scenes": SceneManager.list_scenes(),
        "current": session_manager.get_current_scene()
    }


@router.post("/session/build_prompt")
async def build_prompt(request: BuildPromptRequest):
    """
    æ„å»º LLM æç¤ºè¯ï¼ˆæµ‹è¯•ç”¨ï¼‰
    
    Returns:
        {messages: [...], scene_id, character_name}
    """
    messages = session_manager.build_messages(
        user_input=request.user_input,
        event_type=request.event_type
    )
    
    return {
        "messages": messages,
        "scene_id": session_manager.context.scene_id,
        "character_name": session_manager.context.character_name
    }


@router.get("/session/status")
async def session_status():
    """
    è·å–ä¼šè¯çŠ¶æ€
    
    Returns:
        {active, scene, history_count, character_name, ...}
    """
    return session_manager.get_status()


@router.post("/session/reset")
async def session_reset():
    """
    é‡ç½®ä¼šè¯
    
    æ¸…ç©ºå†å²å’ŒçŠ¶æ€
    
    Returns:
        {success, message}
    """
    session_manager.reset()
    return {
        "success": True,
        "message": "ä¼šè¯å·²é‡ç½®"
    }


@router.post("/session/check_silence")
async def check_silence():
    """
    æ£€æŸ¥æ²‰é»˜äº‹ä»¶
    
    Returns:
        {triggered, event} æˆ– {triggered: false}
    """
    event = session_manager.check_silence()
    
    if event:
        return {
            "triggered": True,
            "event": event
        }
    return {
        "triggered": False
    }


# ===================== é€šè¯è®°å¿†ç®¡ç†æ¥å£ =====================

from .models import CallStartRequest, CallMessageRequest, CallEndRequest
from .call_memory import call_memory


@router.post("/call/start")
async def call_start(request: CallStartRequest):
    """
    å¼€å§‹é€šè¯ï¼Œæ”¶é›†åˆå§‹ä¸Šä¸‹æ–‡
    
    Args:
        request.context: åˆå§‹ä¸Šä¸‹æ–‡ï¼ˆè§’è‰²ã€å†å²ç­‰ï¼‰
        request.filter_config: è¿‡æ»¤é…ç½®ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        {success, call_id, character_name}
    """
    try:
        call_id = call_memory.start(
            initial_context=request.context,
            filter_config=request.filter_config
        )
        
        session = call_memory.get_session(call_id)
        
        return {
            "success": True,
            "call_id": call_id,
            "character_name": session.character_name if session else ""
        }
    except Exception as e:
        print(f"[RealtimeRouter] âŒ å¼€å§‹é€šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/call/message")
async def call_message(request: CallMessageRequest):
    """
    æ·»åŠ é€šè¯æ¶ˆæ¯
    
    Args:
        request.call_id: é€šè¯ID
        request.role: "user" | "assistant"
        request.content: æ¶ˆæ¯å†…å®¹
        
    Returns:
        {success, message_count}
    """
    success = call_memory.add_message(
        call_id=request.call_id,
        role=request.role,
        content=request.content
    )
    
    if not success:
        raise HTTPException(status_code=404, detail="é€šè¯ä¸å­˜åœ¨æˆ–å·²ç»“æŸ")
    
    messages = call_memory.get_messages(request.call_id)
    
    return {
        "success": True,
        "message_count": len(messages)
    }


@router.post("/call/end")
async def call_end(request: CallEndRequest):
    """
    ç»“æŸé€šè¯ï¼Œè¿”å›å…¨éƒ¨è®°å½•ï¼ˆç”¨äºæ³¨å…¥é…’é¦†ï¼‰
    
    Args:
        request.call_id: é€šè¯ID
        
    Returns:
        å®Œæ•´é€šè¯è®°å½•
    """
    result = call_memory.end(request.call_id)
    
    if not result:
        raise HTTPException(status_code=404, detail="é€šè¯ä¸å­˜åœ¨")
    
    return {
        "success": True,
        **result
    }


@router.get("/call/status/{call_id}")
async def call_status(call_id: str):
    """
    è·å–é€šè¯çŠ¶æ€
    
    Args:
        call_id: é€šè¯ID
        
    Returns:
        é€šè¯çŠ¶æ€ä¿¡æ¯
    """
    session = call_memory.get_session(call_id)
    
    if not session:
        raise HTTPException(status_code=404, detail="é€šè¯ä¸å­˜åœ¨")
    
    return session.to_dict()
