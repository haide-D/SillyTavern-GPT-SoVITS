# LLM è¿æ¥æœ€å°æµ‹è¯•å•å…ƒ
# ç”¨æ³•: python test_llm_connection.py
# 
# åŠŸèƒ½: 
# 1. æµ‹è¯•èƒ½å¦ä» Python åç«¯ç›´æ¥è°ƒç”¨ LLM API
# 2. è¯Šæ–­ 502 é”™è¯¯çš„æ ¹æœ¬åŸå› 

import httpx
import asyncio
import json
from typing import Dict


async def test_llm_minimal(
    api_url: str,
    api_key: str,
    model: str = "gpt-4o-mini",
    prompt: str = "ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'"
) -> Dict:
    """
    æœ€å° LLM è°ƒç”¨æµ‹è¯•
    
    è¿”å›è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
    """
    result = {
        "success": False,
        "api_url": api_url,
        "model": model,
        "error": None,
        "response": None,
        "diagnosis": None
    }
    
    # è‡ªåŠ¨è¡¥å…¨ URL
    if '/chat/completions' not in api_url:
        api_url = api_url.rstrip('/') + '/chat/completions'
    
    request_body = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "stream": False
    }
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"  # æ¨¡æ‹Ÿæµè§ˆå™¨
    }
    
    print(f"\n{'='*60}")
    print(f"ğŸ§ª LLM è¿æ¥æµ‹è¯•")
    print(f"{'='*60}")
    print(f"ğŸ“ URL: {api_url}")
    print(f"ğŸ¤– Model: {model}")
    print(f"ğŸ“ Prompt: {prompt[:50]}...")
    print(f"\nğŸ“¤ è¯·æ±‚ä½“:")
    print(json.dumps(request_body, ensure_ascii=False, indent=2))
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            print(f"\nâ³ å‘é€è¯·æ±‚...")
            response = await client.post(
                api_url,
                headers=headers,
                json=request_body
            )
            
            print(f"\nğŸ“¥ å“åº”çŠ¶æ€: {response.status_code}")
            print(f"ğŸ“¥ å“åº”å¤´:")
            for key, value in response.headers.items():
                print(f"   {key}: {value}")
            
            if response.status_code == 200:
                data = response.json()
                content = None
                
                # è§£æå“åº”
                if data.get("choices"):
                    message = data["choices"][0].get("message", {})
                    content = message.get("content", "")
                
                print(f"\nâœ… æˆåŠŸï¼")
                print(f"ğŸ“„ å“åº”å†…å®¹: {content}")
                
                result["success"] = True
                result["response"] = content
                result["diagnosis"] = "LLM API ä» Python åç«¯è°ƒç”¨æ­£å¸¸å·¥ä½œ"
                
            elif response.status_code == 502:
                print(f"\nâŒ 502 Bad Gateway")
                print(f"ğŸ“„ å“åº”å†…å®¹: {response.text[:500]}")
                
                result["error"] = f"502 Bad Gateway"
                result["diagnosis"] = """
502 é”™è¯¯å¯èƒ½çš„åŸå› :
1. API ä»£ç†æœåŠ¡å™¨é—®é¢˜ï¼ˆå¦‚ CloudFlareã€åä»£æœåŠ¡å™¨ï¼‰
2. API æœåŠ¡ä¸æ¥å—æœåŠ¡å™¨ç«¯è¯·æ±‚ï¼ˆUser-Agent æ£€æµ‹ï¼‰
3. API URL é…ç½®é”™è¯¯
4. API KEY æ— æ•ˆæˆ–è¿‡æœŸ

å»ºè®®:
- æ£€æŸ¥ API URL æ˜¯å¦éœ€è¦èµ°ä»£ç†
- å°è¯•ä½¿ç”¨æµè§ˆå™¨ç›´æ¥è®¿é—®æµ‹è¯•
- æ£€æŸ¥ API KEY æ˜¯å¦æœ‰æ•ˆ
"""
            else:
                result["error"] = f"HTTP {response.status_code}: {response.text[:200]}"
                result["diagnosis"] = f"éé¢„æœŸçš„ HTTP çŠ¶æ€ç "
                
    except httpx.ConnectError as e:
        print(f"\nâŒ è¿æ¥é”™è¯¯: {e}")
        result["error"] = f"è¿æ¥å¤±è´¥: {e}"
        result["diagnosis"] = "æ— æ³•è¿æ¥åˆ° API æœåŠ¡å™¨ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– URL æ˜¯å¦æ­£ç¡®"
        
    except httpx.TimeoutException as e:
        print(f"\nâŒ è¶…æ—¶: {e}")
        result["error"] = f"è¯·æ±‚è¶…æ—¶: {e}"
        result["diagnosis"] = "è¯·æ±‚è¶…æ—¶ï¼ŒAPI æœåŠ¡å™¨å“åº”è¿‡æ…¢"
        
    except Exception as e:
        print(f"\nâŒ æœªçŸ¥é”™è¯¯: {type(e).__name__}: {e}")
        result["error"] = f"{type(e).__name__}: {e}"
        result["diagnosis"] = "æœªçŸ¥é”™è¯¯ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æ—¥å¿—"
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š è¯Šæ–­ç»“æœ")
    print(f"{'='*60}")
    print(f"æˆåŠŸ: {result['success']}")
    if result['error']:
        print(f"é”™è¯¯: {result['error']}")
    print(f"è¯Šæ–­: {result['diagnosis']}")
    
    return result


# ============================================================
# é…ç½®åŒº - ä¿®æ”¹è¿™é‡Œçš„å€¼
# ============================================================
if __name__ == "__main__":
    # TODO: ä»ä½ çš„ system_settings.json å¤åˆ¶é…ç½®
    TEST_CONFIG = {
        "api_url": "https://api.openai.com/v1",  # æ”¹æˆä½ çš„ API URL
        "api_key": "sk-xxx",                      # æ”¹æˆä½ çš„ API KEY
        "model": "gpt-4o-mini",                   # æ”¹æˆä½ è¦æµ‹è¯•çš„æ¨¡å‹
    }
    
    print("\n" + "="*60)
    print("âš ï¸  è¯·å…ˆåœ¨ä¸Šæ–¹ TEST_CONFIG ä¸­é…ç½®ä½ çš„ LLM API ä¿¡æ¯ï¼")
    print("="*60 + "\n")
    
    # å¦‚æœé…ç½®æœªä¿®æ”¹ï¼Œå°è¯•ä» system_settings.json è¯»å–
    import os
    import sys
    
    # æ·»åŠ è·¯å¾„
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
    
    try:
        from config import load_json, SETTINGS_FILE
        settings = load_json(SETTINGS_FILE)
        # LLM é…ç½®åœ¨ phone_call.llm è·¯å¾„ä¸‹
        llm_config = settings.get("phone_call", {}).get("llm", {})
        
        if llm_config.get("api_key"):
            TEST_CONFIG = {
                "api_url": llm_config.get("api_url", ""),
                "api_key": llm_config.get("api_key", ""),
                "model": llm_config.get("model", "gpt-4o-mini"),
            }
            print(f"âœ… ä» system_settings.json åŠ è½½é…ç½®:")
            print(f"   API URL: {TEST_CONFIG['api_url']}")
            print(f"   Model: {TEST_CONFIG['model']}")
        else:
            print("âš ï¸  system_settings.json ä¸­æ²¡æœ‰æ‰¾åˆ° LLM é…ç½®")
            print("   è¯·æ‰‹åŠ¨åœ¨è„šæœ¬ä¸­é…ç½® TEST_CONFIG")
            
    except Exception as e:
        print(f"âš ï¸  æ— æ³•è¯»å–é…ç½®æ–‡ä»¶: {e}")
        print("   è¯·æ‰‹åŠ¨åœ¨è„šæœ¬ä¸­é…ç½® TEST_CONFIG")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_llm_minimal(
        api_url=TEST_CONFIG["api_url"],
        api_key=TEST_CONFIG["api_key"],
        model=TEST_CONFIG["model"]
    ))
