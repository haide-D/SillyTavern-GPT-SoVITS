from pydub import AudioSegment
from pydub.effects import normalize
from io import BytesIO
from typing import List, Dict, Optional


class AudioMerger:
    """éŸ³é¢‘åˆå¹¶å·¥å…·"""
    
    @staticmethod
    def merge_segments(
        audio_bytes_list: List[bytes],
        config: Dict,
        pause_durations: Optional[List[Optional[float]]] = None,
        filler_word_audios: Optional[List[Optional[bytes]]] = None
    ) -> bytes:
        """
        åˆå¹¶å¤šæ®µéŸ³é¢‘,æ”¯æŒåŠ¨æ€åœé¡¿å’Œè¯­æ°”è¯æ’å…¥
        
        Args:
            audio_bytes_list: éŸ³é¢‘å­—èŠ‚åˆ—è¡¨
            config: åˆå¹¶é…ç½®
                - silence_between_segments: é»˜è®¤ç‰‡æ®µé—´é™éŸ³æ—¶é•¿(ç§’)
                - normalize_volume: æ˜¯å¦å½’ä¸€åŒ–éŸ³é‡
                - output_format: è¾“å‡ºæ ¼å¼(wav/mp3)
            pause_durations: æ¯ä¸ªç‰‡æ®µåçš„åœé¡¿æ—¶é•¿åˆ—è¡¨(ç§’)
                - é•¿åº¦åº”ä¸ audio_bytes_list ç›¸åŒ
                - None æˆ–å…ƒç´ ä¸º None æ—¶ä½¿ç”¨é»˜è®¤å€¼
                - ç¤ºä¾‹: [0.5, None, 0.8] è¡¨ç¤ºç¬¬1æ®µååœ0.5ç§’,ç¬¬2æ®µç”¨é»˜è®¤,ç¬¬3æ®µåœ0.8ç§’
            filler_word_audios: æ¯ä¸ªç‰‡æ®µåçš„è¯­æ°”è¯éŸ³é¢‘å­—èŠ‚åˆ—è¡¨
                - é•¿åº¦åº”ä¸ audio_bytes_list ç›¸åŒ
                - None æˆ–å…ƒç´ ä¸º None æ—¶ä¸æ’å…¥è¯­æ°”è¯
                - è¯­æ°”è¯ä¼šæ’å…¥åœ¨åœé¡¿ä¹‹å
                - ç¤ºä¾‹: [b'...', None, b'...'] è¡¨ç¤ºç¬¬1æ®µååŠ è¯­æ°”è¯,ç¬¬2æ®µä¸åŠ ,ç¬¬3æ®µåŠ 
        
        Returns:
            åˆå¹¶åçš„éŸ³é¢‘å­—èŠ‚
        
        ç¤ºä¾‹:
            # åŸºç¡€ç”¨æ³•(å‘åå…¼å®¹)
            merged = AudioMerger.merge_segments(audios, config)
            
            # åŠ¨æ€åœé¡¿
            merged = AudioMerger.merge_segments(
                audios, 
                config,
                pause_durations=[0.5, 0.3, 0.8]  # æ¯æ®µè‡ªå®šä¹‰åœé¡¿
            )
            
            # æ·»åŠ è¯­æ°”è¯
            merged = AudioMerger.merge_segments(
                audios,
                config,
                pause_durations=[0.3, 0.2, 0.5],
                filler_word_audios=[filler1_bytes, None, filler2_bytes]
            )
        """
        if not audio_bytes_list:
            raise ValueError("éŸ³é¢‘åˆ—è¡¨ä¸ºç©º")
        
        default_silence_ms = int(config.get("silence_between_segments", 0.3) * 1000)
        normalize_vol = config.get("normalize_volume", True)
        output_fmt = config.get("output_format", "wav")
        
        # åŠ è½½æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
        segments = []
        for audio_bytes in audio_bytes_list:
            segment = AudioSegment.from_file(BytesIO(audio_bytes), format="wav")
            segments.append(segment)
        
        # åŠ è½½è¯­æ°”è¯éŸ³é¢‘(å¦‚æœæä¾›)
        filler_segments = []
        if filler_word_audios:
            for filler_bytes in filler_word_audios:
                if filler_bytes:
                    filler_seg = AudioSegment.from_file(BytesIO(filler_bytes), format="wav")
                    filler_segments.append(filler_seg)
                else:
                    filler_segments.append(None)
        
        # åˆå¹¶éŸ³é¢‘
        merged = segments[0]
        
        for i, seg in enumerate(segments[1:], start=1):
            # ç¡®å®šæ­¤ç‰‡æ®µå‰çš„åœé¡¿æ—¶é•¿
            prev_idx = i - 1
            if pause_durations and prev_idx < len(pause_durations) and pause_durations[prev_idx] is not None:
                silence_ms = int(pause_durations[prev_idx] * 1000)
            else:
                silence_ms = default_silence_ms
            
            # æ·»åŠ åœé¡¿
            silence = AudioSegment.silent(duration=silence_ms)
            merged += silence
            
            # æ·»åŠ è¯­æ°”è¯(å¦‚æœæœ‰)
            if filler_segments and prev_idx < len(filler_segments) and filler_segments[prev_idx]:
                merged += filler_segments[prev_idx]
                # è¯­æ°”è¯åå†åŠ ä¸€å°æ®µåœé¡¿(å¯é€‰,è®©è¯­æ°”è¯æ›´è‡ªç„¶)
                merged += AudioSegment.silent(duration=100)  # 0.1ç§’
            
            # æ·»åŠ å½“å‰ç‰‡æ®µ
            merged += seg
        
        # éŸ³é‡å½’ä¸€åŒ–
        if normalize_vol:
            merged = normalize(merged)
        
        # å¯¼å‡º
        output = BytesIO()
        merged.export(output, format=output_fmt)
        return output.getvalue()
    
    @staticmethod
    def merge_multi_speaker_segments(
        segments: List["MultiSpeakerSegment"],
        audio_bytes_list: List[bytes],
        config: Dict
    ) -> bytes:
        """
        åˆå¹¶å¤šè¯´è¯äººéŸ³é¢‘ï¼Œè¯´è¯äººåˆ‡æ¢æ—¶ä½¿ç”¨æ›´é•¿åœé¡¿
        
        ä¼šåŒæ­¥æ›´æ–° segments ä¸­æ¯ä¸ªå…ƒç´ çš„ start_time å’Œ audio_duration å­—æ®µï¼ˆåŸåœ°ä¿®æ”¹ï¼‰
        
        Args:
            segments: å¤šè¯´è¯äººç‰‡æ®µåˆ—è¡¨ï¼ˆåŒ…å« speaker ä¿¡æ¯ï¼‰
            audio_bytes_list: å¯¹åº”çš„éŸ³é¢‘å­—èŠ‚åˆ—è¡¨
            config: åˆå¹¶é…ç½®
                - speaker_change_pause: è¯´è¯äººåˆ‡æ¢æ—¶çš„åœé¡¿(ç§’)ï¼Œé»˜è®¤ 0.6
                - same_speaker_pause: åŒä¸€è¯´è¯äººå†…çš„åœé¡¿(ç§’)ï¼Œé»˜è®¤ 0.3
                - normalize_volume: æ˜¯å¦å½’ä¸€åŒ–éŸ³é‡
                - output_format: è¾“å‡ºæ ¼å¼(wav/mp3)
                
        Returns:
            åˆå¹¶åçš„éŸ³é¢‘å­—èŠ‚
        """
        from phone_call_utils.models import MultiSpeakerSegment
        
        if not audio_bytes_list:
            raise ValueError("éŸ³é¢‘åˆ—è¡¨ä¸ºç©º")
        
        if len(segments) != len(audio_bytes_list):
            raise ValueError(f"ç‰‡æ®µæ•°({len(segments)})ä¸éŸ³é¢‘æ•°({len(audio_bytes_list)})ä¸åŒ¹é…")
        
        speaker_change_pause_ms = int(config.get("speaker_change_pause", 0.6) * 1000)
        same_speaker_pause_ms = int(config.get("same_speaker_pause", 0.3) * 1000)
        normalize_vol = config.get("normalize_volume", True)
        output_fmt = config.get("output_format", "wav")
        
        # åŠ è½½æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µå¹¶è®¡ç®—æ—¶é•¿
        audio_segments = []
        for audio_bytes in audio_bytes_list:
            audio_seg = AudioSegment.from_file(BytesIO(audio_bytes), format="wav")
            audio_segments.append(audio_seg)
        
        # è®¡ç®—æ¯ä¸ª segment çš„æ—¶é—´ä¿¡æ¯
        current_time_ms = 0
        
        for i, (seg, audio_seg) in enumerate(zip(segments, audio_segments)):
            # æ›´æ–°è¿™ä¸ª segment çš„å¼€å§‹æ—¶é—´å’Œæ—¶é•¿
            seg.start_time = current_time_ms / 1000.0  # è½¬ä¸ºç§’
            seg.audio_duration = len(audio_seg) / 1000.0  # pydub len è¿”å›æ¯«ç§’
            
            # ç´¯åŠ æ—¶é—´ï¼šå½“å‰ç‰‡æ®µæ—¶é•¿
            current_time_ms += len(audio_seg)
            
            # æ·»åŠ åç»­åœé¡¿æ—¶é—´ï¼ˆç”¨äºä¸‹ä¸€ä¸ª segment çš„è®¡ç®—ï¼‰
            if i < len(segments) - 1:
                next_speaker = segments[i + 1].speaker
                current_speaker = seg.speaker
                
                if next_speaker != current_speaker:
                    current_time_ms += speaker_change_pause_ms
                else:
                    if seg.pause_after is not None:
                        current_time_ms += int(seg.pause_after * 1000)
                    else:
                        current_time_ms += same_speaker_pause_ms
        
        # åˆå¹¶éŸ³é¢‘
        merged = audio_segments[0]
        previous_speaker = segments[0].speaker
        
        for i in range(1, len(audio_segments)):
            current_speaker = segments[i].speaker
            prev_segment = segments[i - 1]
            
            # ç¡®å®šåœé¡¿æ—¶é•¿
            if current_speaker != previous_speaker:
                # è¯´è¯äººåˆ‡æ¢ï¼Œä½¿ç”¨æ›´é•¿åœé¡¿
                silence_ms = speaker_change_pause_ms
                print(f"[AudioMerger] è¯´è¯äººåˆ‡æ¢: {previous_speaker} -> {current_speaker}, åœé¡¿ {silence_ms}ms")
            else:
                # åŒä¸€è¯´è¯äººï¼Œä½¿ç”¨è¾ƒçŸ­åœé¡¿
                # ä¼˜å…ˆä½¿ç”¨ segment æŒ‡å®šçš„ pause_after
                if prev_segment.pause_after is not None:
                    silence_ms = int(prev_segment.pause_after * 1000)
                else:
                    silence_ms = same_speaker_pause_ms
            
            # æ·»åŠ åœé¡¿
            silence = AudioSegment.silent(duration=silence_ms)
            merged += silence
            
            # æ·»åŠ å½“å‰ç‰‡æ®µ
            merged += audio_segments[i]
            previous_speaker = current_speaker
        
        # éŸ³é‡å½’ä¸€åŒ–
        if normalize_vol:
            merged = normalize(merged)
        
        # å¯¼å‡º
        output = BytesIO()
        merged.export(output, format=output_fmt)
        
        print(f"[AudioMerger] âœ… å¤šè¯´è¯äººéŸ³é¢‘åˆå¹¶å®Œæˆ: {len(audio_segments)} æ®µ, {len(merged)}ms")
        print(f"[AudioMerger] ğŸ“Š æ—¶é—´ä¿¡æ¯å·²æ›´æ–°åˆ° segments")
        return output.getvalue()

