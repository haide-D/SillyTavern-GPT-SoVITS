from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Optional, Union

from services.phone_call_service import PhoneCallService
from services.llm_service import LLMService
from services.emotion_service import EmotionService
from st_utils.data_extractor import DataExtractor
from phone_call_utils.prompt_builder import PromptBuilder
from phone_call_utils.response_parser import ResponseParser
from config import load_json, SETTINGS_FILE, get_current_dirs, get_sovits_host

router = APIRouter()


def check_phone_call_enabled():
    """æ£€æŸ¥ç”µè¯åŠŸèƒ½æ˜¯å¦å¯ç”¨,å¦‚æœç¦ç”¨åˆ™æŠ›å‡º 403 é”™è¯¯"""
    settings = load_json(SETTINGS_FILE)
    phone_call_config = settings.get("phone_call", {})
    enabled = phone_call_config.get("enabled", True)

    if not enabled:
        raise HTTPException(
            status_code=403,
            detail="ç”µè¯åŠŸèƒ½å·²è¢«ç¦ç”¨ (phone_call.enabled = false)"
        )



class ContextMessage(BaseModel):
    """å¯¹è¯ä¸Šä¸‹æ–‡æ¶ˆæ¯"""
    name: str
    is_user: bool  # å¸ƒå°”å€¼,ä¸æ˜¯å­—ç¬¦ä¸²
    mes: str


class PhoneCallRequest(BaseModel):
    """ä¸»åŠ¨ç”µè¯ç”Ÿæˆè¯·æ±‚"""
    char_name: str
    context: List[Dict[str, str]]


class BuildPromptRequest(BaseModel):
    """æ„å»ºæç¤ºè¯è¯·æ±‚"""
    char_name: str
    context: List[Dict[str, str]]
    user_name: Optional[str] = None  # ç”¨æˆ·åï¼Œç”¨äºåœ¨promptä¸­åŒºåˆ†ç”¨æˆ·èº«ä»½


class ParseAndGenerateRequest(BaseModel):
    """è§£æå¹¶ç”ŸæˆéŸ³é¢‘è¯·æ±‚"""
    char_name: str
    llm_response: str
    generate_audio: Optional[bool] = True  # é»˜è®¤ç”ŸæˆéŸ³é¢‘


class CompleteGenerationRequest(BaseModel):
    """å®Œæˆç”Ÿæˆè¯·æ±‚ (å‰ç«¯è¿”å›LLMå“åº”)"""
    call_id: int
    llm_response: str
    chat_branch: str
    speakers: List[str]
    char_name: Optional[str] = None  # ä¸»è§’è‰²å¡åç§°ï¼Œç”¨äº WebSocket æ¨é€è·¯ç”±


class LLMTestRequest(BaseModel):
    """LLMæµ‹è¯•è¯·æ±‚"""
    api_url: str
    api_key: str
    model: str
    temperature: Optional[float] = 0.8
    max_tokens: Optional[int] = 500
    test_prompt: Optional[str] = "ä½ å¥½,è¯·å›å¤'æµ‹è¯•æˆåŠŸ'"


class MessageWebhookRequest(BaseModel):
    """æ¶ˆæ¯ Webhook è¯·æ±‚"""
    chat_branch: str  # å¯¹è¯åˆ†æ”¯ID
    speakers: List[str]  # è¯´è¯äººåˆ—è¡¨
    current_floor: int  # å½“å‰å¯¹è¯æ¥¼å±‚
    context: List[ContextMessage]  # å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡,ä½¿ç”¨ ContextMessage æ¨¡å‹
    context_fingerprint: str  # ä¸Šä¸‹æ–‡æŒ‡çº¹
    user_name: Optional[str] = None  # ç”¨æˆ·åï¼Œç”¨äºåœ¨promptä¸­åŒºåˆ†ç”¨æˆ·èº«ä»½
    char_name: Optional[str] = None  # ä¸»è§’è‰²å¡åç§°ï¼Œç”¨äº WebSocket æ¨é€è·¯ç”±



@router.post("/phone_call/build_prompt")
async def build_prompt(req: BuildPromptRequest):
    """
    æ„å»ºLLMæç¤ºè¯

    å‰ç«¯è°ƒç”¨æ­¤æ¥å£è·å–æç¤ºè¯,ç„¶åç›´æ¥ç”¨LLM_Clientè°ƒç”¨å¤–éƒ¨LLM

    Args:
        req: åŒ…å«è§’è‰²åå’Œå¯¹è¯ä¸Šä¸‹æ–‡çš„è¯·æ±‚

    Returns:
        åŒ…å«promptå’Œllm_configçš„å­—å…¸
    """
    try:
        check_phone_call_enabled()
        print(f"\n[BuildPrompt] å¼€å§‹æ„å»ºæç¤ºè¯: è§’è‰²={req.char_name}, ä¸Šä¸‹æ–‡={len(req.context)}æ¡æ¶ˆæ¯")

        # åŠ è½½é…ç½®
        settings = load_json(SETTINGS_FILE)
        phone_call_config = settings.get("phone_call", {})

        llm_config = phone_call_config.get("llm", {})
        extractors = phone_call_config.get("data_extractors", [])
        prompt_template = phone_call_config.get("prompt_template", "")
        tts_config = phone_call_config.get("tts_config", {})
        text_lang = tts_config.get("text_lang", "zh")  # è¯»å–è¯­è¨€é…ç½®,é»˜è®¤ä¸­æ–‡

        # æå–ä¸Šä¸‹æ–‡æ•°æ®
        data_extractor = DataExtractor()
        extracted_data = data_extractor.extract(req.context, extractors)

        # è·å–å¯ç”¨æƒ…ç»ª
        emotions = EmotionService.get_available_emotions(req.char_name)

        # æ„å»ºæç¤ºè¯
        prompt_builder = PromptBuilder()
        prompt = prompt_builder.build(
            template=prompt_template,
            char_name=req.char_name,
            context=req.context,
            extracted_data=extracted_data,
            emotions=emotions,
            text_lang=text_lang,  # ä¼ é€’è¯­è¨€é…ç½®
            user_name=req.user_name  # ä¼ é€’ç”¨æˆ·å
        )

        print(f"[BuildPrompt] âœ… æç¤ºè¯æ„å»ºå®Œæˆ: {len(prompt)} å­—ç¬¦")

        return {
            "status": "success",
            "prompt": prompt,
            "llm_config": {
                "api_url": llm_config.get("api_url"),
                "api_key": llm_config.get("api_key"),
                "model": llm_config.get("model"),
                "temperature": llm_config.get("temperature", 0.8),
                "max_tokens": llm_config.get("max_tokens", 5000)
            },
            "emotions": emotions
        }
    except Exception as e:
        print(f"[BuildPrompt] âŒ é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/phone_call/parse_and_generate")
async def parse_and_generate(req: ParseAndGenerateRequest):
    """
    è§£æLLMå“åº”å¹¶ç”ŸæˆéŸ³é¢‘

    å‰ç«¯è°ƒç”¨LLMå,å°†å“åº”å‘é€åˆ°æ­¤æ¥å£è¿›è¡Œè§£æå’ŒéŸ³é¢‘ç”Ÿæˆ

    Args:
        req: åŒ…å«è§’è‰²åã€LLMå“åº”å’Œæ˜¯å¦ç”ŸæˆéŸ³é¢‘çš„è¯·æ±‚

    Returns:
        åŒ…å«segmentså’Œaudio(å¯é€‰)çš„å­—å…¸
    """
    try:
        check_phone_call_enabled()
        print(f"\n[ParseAndGenerate] å¼€å§‹è§£æ: è§’è‰²={req.char_name}, å“åº”é•¿åº¦={len(req.llm_response)} å­—ç¬¦")

        # åŠ è½½é…ç½®
        settings = load_json(SETTINGS_FILE)
        phone_call_config = settings.get("phone_call", {})

        parser_config = phone_call_config.get("response_parser", {})

        # è·å–å¯ç”¨æƒ…ç»ª
        emotions = EmotionService.get_available_emotions(req.char_name)

        # è§£æå“åº” - ä¼˜å…ˆä½¿ç”¨ JSON æ ¼å¼,å¸¦è¶…æ—¶ä¿æŠ¤
        import asyncio

        response_parser = ResponseParser()
        parse_format = parser_config.get("format", "json")  # é»˜è®¤ä½¿ç”¨ JSON

        # å®šä¹‰å¼‚æ­¥åŒ…è£…å™¨ä»¥æ”¯æŒè¶…æ—¶æ§åˆ¶
        async def parse_with_timeout():
            if parse_format == "json":
                print(f"[ParseAndGenerate] ä½¿ç”¨ JSON æ ¼å¼è§£æ")
                return response_parser.parse_json_response(
                    req.llm_response,
                    parser_config,
                    available_emotions=emotions
                )
            else:
                print(f"[ParseAndGenerate] ä½¿ç”¨æ­£åˆ™æ ¼å¼è§£æ")
                return response_parser.parse_emotion_segments(
                    req.llm_response,
                    parser_config,
                    available_emotions=emotions
                )

        # å¸¦è¶…æ—¶å’Œé‡è¯•çš„è§£æ
        max_retries = 1
        timeout_seconds = 90
        segments = None

        for attempt in range(max_retries + 1):
            try:
                print(f"[ParseAndGenerate] å¼€å§‹è§£æ (å°è¯• {attempt + 1}/{max_retries + 1}, è¶…æ—¶é™åˆ¶: {timeout_seconds}ç§’)")
                segments = await asyncio.wait_for(parse_with_timeout(), timeout=timeout_seconds)
                print(f"[ParseAndGenerate] âœ… è§£ææˆåŠŸ")
                break
            except asyncio.TimeoutError:
                if attempt < max_retries:
                    print(f"[ParseAndGenerate] âš ï¸ è§£æè¶…æ—¶ ({timeout_seconds}ç§’),æ­£åœ¨é‡è¯•...")
                else:
                    print(f"[ParseAndGenerate] âŒ è§£æè¶…æ—¶ä¸”é‡è¯•å¤±è´¥")
                    raise HTTPException(status_code=504, detail=f"è§£æå“åº”è¶…æ—¶ (>{timeout_seconds}ç§’)")
            except Exception as e:
                print(f"[ParseAndGenerate] âŒ è§£æå¤±è´¥: {str(e)}")
                raise

        if segments is None:
            raise HTTPException(status_code=500, detail="è§£æå¤±è´¥,æœªè·å–åˆ°æœ‰æ•ˆç‰‡æ®µ")

        print(f"[ParseAndGenerate] è§£æåˆ° {len(segments)} ä¸ªæƒ…ç»ªç‰‡æ®µ")

        result = {
            "status": "success",
            "segments": [seg.dict() for seg in segments],
            "total_segments": len(segments)
        }

        # è°ƒè¯•æ—¥å¿—
        print(f"[ParseAndGenerate] generate_audio={req.generate_audio}, segments={len(segments)}")

        # å¦‚æœéœ€è¦ç”ŸæˆéŸ³é¢‘,è°ƒç”¨TTSæœåŠ¡
        if req.generate_audio and segments:
            print(f"[ParseAndGenerate] å¼€å§‹ç”ŸæˆéŸ³é¢‘...")

            # åŠ è½½TTSå’ŒéŸ³é¢‘åˆå¹¶é…ç½®
            tts_config = phone_call_config.get("tts_config", {})
            audio_merge_config = phone_call_config.get("audio_merge", {})

            # å¯¼å…¥TTSç›¸å…³æ¨¡å—
            from phone_call_utils.tts_service import TTSService
            from phone_call_utils.audio_merger import AudioMerger
            from config import get_sovits_host

            tts_service = TTSService(get_sovits_host())
            audio_merger = AudioMerger()
            audio_bytes_list = []

            # è¿½è¸ªä¸Šä¸€ä¸ªæƒ…ç»ªå’Œå‚è€ƒéŸ³é¢‘,ç”¨äºæƒ…ç»ªå˜åŒ–æ—¶çš„éŸ³è‰²èåˆ
            previous_emotion = None
            previous_ref_audio = None

            # ğŸ”§ ä½¿ç”¨æ¨¡å‹é”ï¼Œç¡®ä¿ç”ŸæˆæœŸé—´ä¸ä¼šè¢«å…¶ä»–è¯·æ±‚åˆ‡æ¢æƒé‡
            async with model_weight_service.use_model(req.char_name, f"parse_generate_{req.char_name}") as switch_success:
                if not switch_success:
                    print(f"[ParseAndGenerate] âš ï¸ æƒé‡åˆ‡æ¢å¤±è´¥ï¼Œå°†ä½¿ç”¨å½“å‰åŠ è½½çš„æ¨¡å‹ç»§ç»­ç”Ÿæˆ")

                for i, segment in enumerate(segments):
                    print(f"[ParseAndGenerate] ç”Ÿæˆç‰‡æ®µ {i+1}/{len(segments)}: [{segment.emotion}] {segment.text[:30]}...")

                    # é€‰æ‹©å‚è€ƒéŸ³é¢‘
                    ref_audio = _select_ref_audio(req.char_name, segment.emotion)

                    if not ref_audio:
                        print(f"[ParseAndGenerate] è­¦å‘Š: æœªæ‰¾åˆ°æƒ…ç»ª '{segment.emotion}' çš„å‚è€ƒéŸ³é¢‘,è·³è¿‡")
                        continue

                    # æ£€æµ‹æƒ…ç»ªå˜åŒ–
                    emotion_changed = previous_emotion is not None and previous_emotion != segment.emotion
                    if emotion_changed:
                        print(f"[ParseAndGenerate] æ£€æµ‹åˆ°æƒ…ç»ªå˜åŒ–: {previous_emotion} -> {segment.emotion}")

                    # ç”ŸæˆéŸ³é¢‘ - å¦‚æœæƒ…ç»ªå˜åŒ–,ä¼ å…¥ä¸Šä¸€ä¸ªæƒ…ç»ªçš„å‚è€ƒéŸ³é¢‘è¿›è¡ŒéŸ³è‰²èåˆ
                    try:
                        audio_bytes = await tts_service.generate_audio(
                            segment=segment,
                            ref_audio=ref_audio,
                            tts_config=tts_config,
                            previous_ref_audio=previous_ref_audio if emotion_changed else None
                        )
                        audio_bytes_list.append(audio_bytes)
                        print(f"[ParseAndGenerate] âœ… ç‰‡æ®µ {i+1} ç”ŸæˆæˆåŠŸ: {len(audio_bytes)} å­—èŠ‚")

                        # æ›´æ–°ä¸Šä¸€ä¸ªæƒ…ç»ªå’Œå‚è€ƒéŸ³é¢‘
                        previous_emotion = segment.emotion
                        previous_ref_audio = ref_audio

                    except Exception as e:
                        print(f"[ParseAndGenerate] âŒ ç”ŸæˆéŸ³é¢‘å¤±è´¥ - {e}")
                        continue

            # åˆå¹¶éŸ³é¢‘ (é”å·²é‡Šæ”¾ï¼Œåˆå¹¶ä¸éœ€è¦æ¨¡å‹)
            if audio_bytes_list:
                print(f"[ParseAndGenerate] åˆå¹¶ {len(audio_bytes_list)} æ®µéŸ³é¢‘...")
                try:
                    # ç›´æ¥ä½¿ç”¨ segments ä¸­çš„åœé¡¿é…ç½®(ç”± LLM æ™ºèƒ½å†³å®š)
                    pause_durations = [seg.pause_after for seg in segments[:len(audio_bytes_list)]]

                    # æå–è¯­æ°”è¯é…ç½®å¹¶ç”Ÿæˆå¯¹åº”éŸ³é¢‘
                    # æ³¨æ„: è¿™é‡Œåªæ˜¯å ä½é€»è¾‘,å®é™…è¯­æ°”è¯éŸ³é¢‘éœ€è¦é€šè¿‡TTSç”Ÿæˆ
                    # ä½ å¯ä»¥åœ¨è¿™é‡Œè°ƒç”¨ tts_service ä¸ºè¯­æ°”è¯ç”ŸæˆéŸ³é¢‘
                    filler_word_audios = []
                    for i, segment in enumerate(segments[:len(audio_bytes_list)]):
                        if segment.filler_word:
                            # TODO: è°ƒç”¨TTSç”Ÿæˆè¯­æ°”è¯éŸ³é¢‘
                            # filler_audio = await tts_service.generate_audio(...)
                            # filler_word_audios.append(filler_audio)
                            print(f"[ParseAndGenerate] ç‰‡æ®µ {i+1} éœ€è¦è¯­æ°”è¯: '{segment.filler_word}'")
                            filler_word_audios.append(None)  # æš‚æ—¶å ä½
                        else:
                            filler_word_audios.append(None)

                    # åˆå¹¶éŸ³é¢‘,ä¼ å…¥åŠ¨æ€åœé¡¿å’Œè¯­æ°”è¯é…ç½®
                    merged_audio = audio_merger.merge_segments(
                        audio_bytes_list,
                        audio_merge_config,
                        pause_durations=pause_durations,
                        filler_word_audios=filler_word_audios
                    )

                    # å°†éŸ³é¢‘å­—èŠ‚æ•°æ®è½¬æ¢ä¸º base64 ç¼–ç ,ä»¥ä¾¿ JSON åºåˆ—åŒ–
                    import base64
                    audio_base64 = base64.b64encode(merged_audio).decode('utf-8')

                    result["audio"] = audio_base64
                    result["audio_format"] = audio_merge_config.get("output_format", "wav")
                    print(f"[ParseAndGenerate] âœ… éŸ³é¢‘åˆå¹¶å®Œæˆ: {len(merged_audio)} å­—èŠ‚ (base64: {len(audio_base64)} å­—ç¬¦)")
                except Exception as e:
                    print(f"[ParseAndGenerate] âŒ åˆå¹¶éŸ³é¢‘å¤±è´¥ - {e}")
            else:
                print(f"[ParseAndGenerate] âš ï¸ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•éŸ³é¢‘ç‰‡æ®µ")

        return result

    except Exception as e:
        print(f"[ParseAndGenerate] âŒ é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/phone_call/complete_generation")
async def complete_generation(req: CompleteGenerationRequest):
    """
    å®Œæˆè‡ªåŠ¨ç”µè¯ç”Ÿæˆ (æ–°æ¶æ„ - ç¬¬äºŒé˜¶æ®µ)

    å‰ç«¯è°ƒç”¨LLMå,å°†å“åº”å‘é€åˆ°æ­¤ç«¯ç‚¹å®ŒæˆéŸ³é¢‘ç”Ÿæˆ

    æµç¨‹:
    1. æ¥æ”¶å‰ç«¯çš„LLMå“åº”
    2. è§£æå“åº”å¹¶éªŒè¯è¯´è¯äºº
    3. ç”ŸæˆéŸ³é¢‘
    4. æ›´æ–°æ•°æ®åº“
    5. é€šè¿‡WebSocketé€šçŸ¥å‰ç«¯å®Œæˆ

    Args:
        req: åŒ…å«call_idã€LLMå“åº”ã€è¯´è¯äººåˆ—è¡¨ç­‰

    Returns:
        ç”Ÿæˆç»“æœ
    """
    try:
        check_phone_call_enabled()
        from database import DatabaseManager
        from services.auto_call_scheduler import AutoCallScheduler
        import json

        print(f"\n[CompleteGeneration] æ”¶åˆ°LLMå“åº”: call_id={req.call_id}")
        print(f"[CompleteGeneration] LLMå“åº”é•¿åº¦: {len(req.llm_response)} å­—ç¬¦")
        print(f"[CompleteGeneration] LLMå“åº”å†…å®¹ (å‰500å­—ç¬¦): {req.llm_response[:500]}")

        db = DatabaseManager()
        scheduler = AutoCallScheduler()

        # æ¸…ç† markdown ä»£ç å— (å¦‚æœå­˜åœ¨)
        llm_response_cleaned = req.llm_response.strip()

        # æ£€æµ‹å¹¶ç§»é™¤ markdown ä»£ç å—æ ‡è®°
        import re
        # åŒ¹é… ```json ... ``` æˆ– ``` ... ```
        markdown_pattern = r'^```(?:json)?\s*\n(.*?)\n```$'
        match = re.match(markdown_pattern, llm_response_cleaned, re.DOTALL)

        if match:
            llm_response_cleaned = match.group(1).strip()
            print(f"[CompleteGeneration] æ£€æµ‹åˆ° markdown ä»£ç å—,å·²æ¸…ç†")
            print(f"[CompleteGeneration] æ¸…ç†åå†…å®¹ (å‰500å­—ç¬¦): {llm_response_cleaned[:500]}")

        # è§£æLLMå“åº”
        try:
            response_data = json.loads(llm_response_cleaned)
            print(f"[CompleteGeneration] âœ… JSONè§£ææˆåŠŸ")
        except json.JSONDecodeError as e:
            print(f"[CompleteGeneration] âŒ JSONè§£æå¤±è´¥: {str(e)}")
            print(f"[CompleteGeneration] å®Œæ•´å“åº”å†…å®¹: {llm_response_cleaned}")
            raise ValueError(f"LLMå“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {str(e)}")
        selected_speaker = response_data.get("speaker")

        # éªŒè¯è¯´è¯äºº
        if not selected_speaker or selected_speaker not in req.speakers:
            raise ValueError(f"LLMè¿”å›çš„è¯´è¯äºº '{selected_speaker}' æ— æ•ˆ,å¯ç”¨è¯´è¯äºº: {req.speakers}")

        print(f"[CompleteGeneration] LLMé€‰æ‹©çš„è¯´è¯äºº: {selected_speaker}")

        # è·å–è¯¥è¯´è¯äººçš„å¯ç”¨æƒ…ç»ª
        emotion_service = EmotionService()
        available_emotions = emotion_service.get_available_emotions(selected_speaker)

        # è§£ææƒ…ç»ªç‰‡æ®µ - ä½¿ç”¨ JSON è§£æå™¨
        parser = ResponseParser()
        settings = load_json(SETTINGS_FILE)
        parser_config = settings.get("phone_call", {}).get("response_parser", {})

        # ä½¿ç”¨ parse_json_response è€Œä¸æ˜¯ parse_emotion_segments
        # å› ä¸º LLM è¿”å›çš„æ˜¯ JSON æ ¼å¼
        segments = parser.parse_json_response(
            llm_response_cleaned,  # ä½¿ç”¨æ¸…ç†åçš„å“åº”
            parser_config,
            available_emotions=available_emotions
        )

        print(f"[CompleteGeneration] è§£æåˆ° {len(segments)} ä¸ªæƒ…ç»ªç‰‡æ®µ")

        # ç”ŸæˆéŸ³é¢‘
        from phone_call_utils.tts_service import TTSService
        from phone_call_utils.audio_merger import AudioMerger
        from config import get_sovits_host

        tts_service = TTSService(get_sovits_host())
        audio_merger = AudioMerger()

        tts_config = settings.get("phone_call", {}).get("tts_config", {})
        audio_merge_config = settings.get("phone_call", {}).get("audio_merge", {})

        audio_bytes_list = []
        previous_emotion = None
        previous_ref_audio = None

        # ğŸ”§ ä½¿ç”¨æ¨¡å‹é”ï¼Œç¡®ä¿ç”ŸæˆæœŸé—´ä¸ä¼šè¢«å…¶ä»–è¯·æ±‚åˆ‡æ¢æƒé‡
        async with model_weight_service.use_model(selected_speaker, f"phone_call_{req.call_id}") as switch_success:
            if not switch_success:
                print(f"[CompleteGeneration] âš ï¸ æƒé‡åˆ‡æ¢å¤±è´¥ï¼Œå°†ä½¿ç”¨å½“å‰åŠ è½½çš„æ¨¡å‹ç»§ç»­ç”Ÿæˆ")

            for i, segment in enumerate(segments):
                print(f"[CompleteGeneration] ç”Ÿæˆç‰‡æ®µ {i+1}/{len(segments)}: [{segment.emotion}] {segment.text[:30]}...")

                # é€‰æ‹©å‚è€ƒéŸ³é¢‘
                ref_audio = _select_ref_audio(selected_speaker, segment.emotion)

                if not ref_audio:
                    print(f"[CompleteGeneration] è­¦å‘Š: æœªæ‰¾åˆ°æƒ…ç»ª '{segment.emotion}' çš„å‚è€ƒéŸ³é¢‘,è·³è¿‡")
                    continue

                # æ£€æµ‹æƒ…ç»ªå˜åŒ–
                emotion_changed = previous_emotion is not None and previous_emotion != segment.emotion

                # ç”ŸæˆéŸ³é¢‘
                try:
                    audio_bytes = await tts_service.generate_audio(
                        segment=segment,
                        ref_audio=ref_audio,
                        tts_config=tts_config,
                        previous_ref_audio=previous_ref_audio if emotion_changed else None
                    )

                    # è·å–éŸ³é¢‘æ—¶é•¿(ç”¨äºéŸ³è½¨åŒæ­¥)
                    from pydub import AudioSegment as PydubSegment
                    from io import BytesIO
                    audio_seg = PydubSegment.from_file(BytesIO(audio_bytes), format="wav")
                    duration_seconds = len(audio_seg) / 1000.0  # æ¯«ç§’è½¬ç§’
                    segment.audio_duration = duration_seconds
                    print(f"[CompleteGeneration] éŸ³é¢‘æ—¶é•¿: {duration_seconds:.2f}ç§’")

                    audio_bytes_list.append(audio_bytes)

                    previous_emotion = segment.emotion
                    previous_ref_audio = ref_audio

                except Exception as e:
                    print(f"[CompleteGeneration] é”™è¯¯: ç”ŸæˆéŸ³é¢‘å¤±è´¥ - {e}")
                    continue

        # åˆå¹¶éŸ³é¢‘ (é”å·²é‡Šæ”¾ï¼Œåˆå¹¶ä¸éœ€è¦æ¨¡å‹)
        audio_path = None
        audio_url = None
        if audio_bytes_list:
            print(f"[CompleteGeneration] åˆå¹¶ {len(audio_bytes_list)} æ®µéŸ³é¢‘...")
            merged_audio = audio_merger.merge_segments(audio_bytes_list, audio_merge_config)

            # ä¿å­˜éŸ³é¢‘å¹¶è·å– URL
            audio_path, audio_url = await scheduler._save_audio(
                req.call_id,
                selected_speaker,
                merged_audio,
                audio_merge_config.get("output_format", "wav")
            )

            # è®¡ç®—æ¯ä¸ªsegmentçš„èµ·å§‹æ—¶é—´(ç”¨äºéŸ³è½¨åŒæ­¥)
            current_time = 0.0
            default_pause = audio_merge_config.get("silence_between_segments", 0.3)
            for i, segment in enumerate(segments):
                segment.start_time = current_time

                # ç´¯åŠ æ—¶é—´: éŸ³é¢‘æ—¶é•¿ + åœé¡¿æ—¶é•¿
                if segment.audio_duration:
                    current_time += segment.audio_duration

                # æ·»åŠ åœé¡¿æ—¶é•¿(æœ€åä¸€ä¸ªsegmentä¸æ·»åŠ )
                if i < len(segments) - 1:
                    pause = segment.pause_after if segment.pause_after is not None else default_pause
                    current_time += pause

            print(f"[CompleteGeneration] âœ… éŸ³è½¨åŒæ­¥ä¿¡æ¯å·²è®¡ç®—: {len(segments)}ä¸ªç‰‡æ®µ")


        # æ›´æ–°æ•°æ®åº“(åŒæ—¶æ›´æ–° char_name ä¸º LLM é€‰æ‹©çš„è¯´è¯äºº)
        conn = db._get_connection()
        cursor = conn.cursor()
        try:
            cursor.execute(
                "UPDATE auto_phone_calls SET status = ?, char_name = ?, audio_path = ?, audio_url = ?, segments = ? WHERE id = ?",
                ("completed", selected_speaker, audio_path, audio_url, json.dumps([seg.dict() for seg in segments], ensure_ascii=False), req.call_id)
            )
            conn.commit()
        finally:
            conn.close()

        print(f"[CompleteGeneration] âœ… ç”Ÿæˆå®Œæˆ: call_id={req.call_id}, speaker={selected_speaker}, audio={audio_path}, url={audio_url}")

        # é€šçŸ¥å‰ç«¯å®Œæˆ
        # WebSocket æ¨é€ç›®æ ‡: ä¼˜å…ˆä½¿ç”¨å‰ç«¯ä¼ é€’çš„ä¸»è§’è‰²å,å›é€€åˆ° selected_speaker
        ws_target = req.char_name if req.char_name else selected_speaker
        print(f"[CompleteGeneration] WebSocket æ¨é€ç›®æ ‡: {ws_target}")

        from services.notification_service import NotificationService
        notification_service = NotificationService()
        await notification_service.notify_phone_call_ready(
            char_name=ws_target,  # ä½¿ç”¨ä¸»è§’è‰²å¡åç§°è¿›è¡Œ WebSocket è·¯ç”±
            call_id=req.call_id,
            segments=[seg.dict() for seg in segments],
            audio_path=audio_path,
            audio_url=audio_url,
            selected_speaker=selected_speaker  # LLM é€‰æ‹©çš„å®é™…æ‰“ç”µè¯äºº
        )

        # ç§»é™¤è¿è¡Œä¸­æ ‡è®°(ä½¿ç”¨ trigger_floor)
        # éœ€è¦ä» call_id è·å– trigger_floor
        conn = db._get_connection()
        cursor = conn.cursor()
        try:
            cursor.execute("SELECT trigger_floor FROM auto_phone_calls WHERE id = ?", (req.call_id,))
            row = cursor.fetchone()
            if row and hasattr(scheduler, '_running_tasks'):
                trigger_floor = row[0]
                scheduler._running_tasks.discard(trigger_floor)
                print(f"[CompleteGeneration] ç§»é™¤è¿è¡Œä¸­ä»»åŠ¡: æ¥¼å±‚{trigger_floor}")
        finally:
            conn.close()

        return {
            "status": "success",
            "message": "ç”Ÿæˆå®Œæˆ",
            "call_id": req.call_id,
            "selected_speaker": selected_speaker,
            "segments": [seg.dict() for seg in segments],
            "audio_path": audio_path,
            "audio_url": audio_url
        }

    except Exception as e:
        print(f"[CompleteGeneration] âŒ å¤±è´¥: {str(e)}")

        # æ›´æ–°çŠ¶æ€ä¸º failed
        try:
            db.update_auto_call_status(
                call_id=req.call_id,
                status="failed",
                error_message=str(e)
            )
            print(f"[CompleteGeneration] å·²æ›´æ–°çŠ¶æ€ä¸º failed")
        except Exception as update_error:
            print(f"[CompleteGeneration] æ›´æ–°çŠ¶æ€å¤±è´¥: {str(update_error)}")

        # ç§»é™¤è¿è¡Œä¸­æ ‡è®°
        try:
            conn = db._get_connection()
            cursor = conn.cursor()
            try:
                cursor.execute("SELECT trigger_floor FROM auto_phone_calls WHERE id = ?", (req.call_id,))
                row = cursor.fetchone()
                if row and hasattr(scheduler, '_running_tasks'):
                    trigger_floor = row[0]
                    scheduler._running_tasks.discard(trigger_floor)
                    print(f"[CompleteGeneration] å·²ç§»é™¤è¿è¡Œä¸­ä»»åŠ¡: æ¥¼å±‚{trigger_floor}")
            finally:
                conn.close()
        except Exception as cleanup_error:
            print(f"[CompleteGeneration] æ¸…ç†è¿è¡Œä¸­æ ‡è®°å¤±è´¥: {str(cleanup_error)}")

        raise HTTPException(status_code=500, detail=str(e))




def _select_ref_audio(char_name: str, emotion: str) -> Optional[Dict]:
    """
    æ ¹æ®æƒ…ç»ªé€‰æ‹©å‚è€ƒéŸ³é¢‘

    Args:
        char_name: è§’è‰²åç§°
        emotion: æƒ…ç»ªåç§°

    Returns:
        å‚è€ƒéŸ³é¢‘ä¿¡æ¯ {path, text} æˆ– None
    """
    import os
    import random
    from config import get_current_dirs
    from utils import scan_audio_files

    # è·å–è§’è‰²æ¨¡å‹æ–‡ä»¶å¤¹
    mappings = load_json(os.path.join(os.path.dirname(SETTINGS_FILE), "character_mappings.json"))

    if char_name not in mappings:
        print(f"[_select_ref_audio] é”™è¯¯: è§’è‰² {char_name} æœªç»‘å®šæ¨¡å‹")
        return None

    model_folder = mappings[char_name]
    base_dir, _ = get_current_dirs()

    # ä» tts_config.prompt_lang è¯»å–è¯­è¨€è®¾ç½®å¹¶è½¬æ¢ä¸ºç›®å½•å
    settings = load_json(SETTINGS_FILE)
    prompt_lang = settings.get("phone_call", {}).get("tts_config", {}).get("prompt_lang", "zh")

    # è¯­è¨€ä»£ç è½¬ç›®å½•åæ˜ å°„
    lang_map = {
        "zh": "Chinese",
        "en": "English",
        "ja": "Japanese",
        "all_zh": "Chinese",
        "all_ja": "Japanese"
    }
    lang_dir = lang_map.get(prompt_lang, "Chinese")

    # ä½¿ç”¨é…ç½®çš„è¯­è¨€ç›®å½•
    ref_dir = os.path.join(base_dir, model_folder, "reference_audios", lang_dir, "emotions")

    if not os.path.exists(ref_dir):
        print(f"[_select_ref_audio] é”™è¯¯: å‚è€ƒéŸ³é¢‘ç›®å½•ä¸å­˜åœ¨: {ref_dir}")
        return None

    # æ‰«æéŸ³é¢‘æ–‡ä»¶
    audio_files = scan_audio_files(ref_dir)

    # ç­›é€‰åŒ¹é…æƒ…ç»ªçš„éŸ³é¢‘
    matching_audios = [a for a in audio_files if a["emotion"] == emotion]

    if not matching_audios:
        print(f"[_select_ref_audio] è­¦å‘Š: æœªæ‰¾åˆ°æƒ…ç»ª '{emotion}' çš„å‚è€ƒéŸ³é¢‘")
        return None

    # éšæœºé€‰æ‹©ä¸€ä¸ª
    selected = random.choice(matching_audios)

    return {
        "path": selected["path"],
        "text": selected["text"]
    }


# ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹æƒé‡ç®¡ç†æœåŠ¡
from services.model_weight_service import model_weight_service


@router.post("/phone_call/generate")
async def generate_phone_call(req: PhoneCallRequest):
    """
    ç”Ÿæˆä¸»åŠ¨ç”µè¯å†…å®¹ (ä¿ç•™åŸæ¥å£ä½œä¸ºå…¼å®¹,ä½†ä¸æ¨èä½¿ç”¨)

    Args:
        req: åŒ…å«è§’è‰²åå’Œå¯¹è¯ä¸Šä¸‹æ–‡çš„è¯·æ±‚

    Returns:
        åŒ…å«segmentsã€audio(å¯é€‰)ç­‰ä¿¡æ¯çš„å­—å…¸
    """
    try:
        check_phone_call_enabled()
        service = PhoneCallService()
        result = await service.generate(req.char_name, req.context)

        return {
            "status": "success",
            **result  # å±•å¼€resultä¸­çš„æ‰€æœ‰å­—æ®µ
        }
    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/phone_call/emotions/{char_name}")
def get_emotions(char_name: str):
    """
    è·å–è§’è‰²å¯ç”¨æƒ…ç»ªåˆ—è¡¨

    Args:
        char_name: è§’è‰²åç§°

    Returns:
        æƒ…ç»ªåˆ—è¡¨
    """
    try:
        check_phone_call_enabled()
        emotions = EmotionService.get_available_emotions(char_name)
        return {
            "status": "success",
            "char_name": char_name,
            "emotions": emotions
        }
    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/phone_call/test_llm")
async def test_llm(req: LLMTestRequest):
    """
    æµ‹è¯•LLMè¿æ¥

    Args:
        req: LLMæµ‹è¯•é…ç½®

    Returns:
        æµ‹è¯•ç»“æœ
    """
    check_phone_call_enabled()
    return await LLMService.test_connection(req.dict())


# ==================== è‡ªåŠ¨ç”Ÿæˆç›¸å…³æ¥å£ ====================

@router.post("/phone_call/webhook/message")
async def message_webhook(req: MessageWebhookRequest):
    """
    æ¥æ”¶ SillyTavern æ¶ˆæ¯ webhook

    å½“ç”¨æˆ·å‘é€æ¶ˆæ¯æ—¶,SillyTavern è°ƒç”¨æ­¤æ¥å£,è§¦å‘è‡ªåŠ¨ç”Ÿæˆæ£€æµ‹
    
    æ–°æµç¨‹ï¼ˆåŸºäº LLM åœºæ™¯åˆ†æï¼‰:
    1. æ£€æŸ¥è§¦å‘æ¡ä»¶
    2. æ„å»ºåœºæ™¯åˆ†æ prompt
    3. é€šè¿‡ WebSocket å‘é€ç»™å‰ç«¯è°ƒç”¨ LLM
    4. å‰ç«¯è¿”å›åˆ†æç»“æœåˆ° /scene_analysis/complete
    5. æ ¹æ®ç»“æœåˆ†æµåˆ° phone_call æˆ– eavesdrop

    Args:
        req: åŒ…å«å¯¹è¯åˆ†æ”¯ã€è¯´è¯äººåˆ—è¡¨ã€å½“å‰æ¥¼å±‚å’Œå¯¹è¯ä¸Šä¸‹æ–‡

    Returns:
        å¤„ç†ç»“æœ
    """
    try:
        check_phone_call_enabled()
        from services.conversation_monitor import ConversationMonitor
        from services.scene_analyzer import SceneAnalyzer
        from services.notification_service import NotificationService
        import uuid

        # æ·»åŠ è¯¦ç»†çš„è¯·æ±‚æ—¥å¿—
        print(f"\n[Webhook] æ”¶åˆ°è¯·æ±‚:")
        print(f"  - chat_branch: {req.chat_branch}")
        print(f"  - speakers: {req.speakers}")
        print(f"  - current_floor: {req.current_floor}")
        print(f"  - context æ¡æ•°: {len(req.context)}")
        if req.context:
            print(f"  - context ç¤ºä¾‹ (å‰2æ¡): {req.context[:2]}")

        print(f"\n[Webhook] æ”¶åˆ°æ¶ˆæ¯: chat_branch={req.chat_branch}, è¯´è¯äºº={req.speakers}, æ¥¼å±‚={req.current_floor}")

        # å¦‚æœæ²¡æœ‰è¯´è¯äºº,è·³è¿‡
        if not req.speakers or len(req.speakers) == 0:
            return {
                "status": "skipped",
                "message": "æ²¡æœ‰å¯ç”¨çš„è¯´è¯äºº"
            }

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¯´è¯äººä½œä¸ºä¸»è¦è§’è‰² (ç”¨äºè§¦å‘æ£€æµ‹)
        primary_speaker = req.speakers[0]

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘
        monitor = ConversationMonitor()

        if not monitor.should_trigger(primary_speaker, req.current_floor):
            return {
                "status": "skipped",
                "message": "æœªè¾¾åˆ°è§¦å‘æ¡ä»¶"
            }

        # æå–ä¸Šä¸‹æ–‡
        context = monitor.extract_context(req.context)
        trigger_floor = monitor.get_trigger_floor(req.current_floor)
        
        # ==================== æŸ¥è¯¢é€šè¯å†å² ====================
        from database import DatabaseManager
        db = DatabaseManager()
        
        # è·å–è¿‘æœŸé€šè¯å†å²ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦é‡å¤è§¦å‘ï¼‰
        call_history = []
        if req.context_fingerprint:
            # ä½¿ç”¨æŒ‡çº¹æŸ¥è¯¢
            call_history = db.get_auto_call_history_by_fingerprints(
                fingerprints=[req.context_fingerprint],
                limit=5
            )
            if call_history:
                print(f"[Webhook] ğŸ“ æ£€æµ‹åˆ° {len(call_history)} æ¡é€šè¯å†å²è®°å½•")
        
        # ==================== åœºæ™¯åˆ†æ (LLM ç‰ˆ) ====================
        analyzer = SceneAnalyzer()
        print(f"[Webhook] ğŸ” æ„å»ºåœºæ™¯åˆ†æè¯·æ±‚...")
        
        # æ„å»ºåœºæ™¯åˆ†æ promptï¼ˆä¼ å…¥é€šè¯å†å²ï¼‰
        analysis_data = await analyzer.analyze(
            context=context,
            speakers=req.speakers,
            char_name=primary_speaker,
            user_name=req.user_name,
            call_history=call_history
        )
        
        # ç”Ÿæˆå”¯ä¸€è¯·æ±‚ ID
        request_id = str(uuid.uuid4())
        
        # WebSocket è·¯ç”±ç›®æ ‡
        ws_target = req.char_name if req.char_name else primary_speaker
        
        # è½¬æ¢ context ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        context_serializable = [
            {"name": c.name, "is_user": c.is_user, "mes": c.mes} 
            if hasattr(c, 'name') else c 
            for c in context
        ]
        
        # é€šè¿‡ WebSocket é€šçŸ¥å‰ç«¯è°ƒç”¨ LLM è¿›è¡Œåœºæ™¯åˆ†æ
        notification_service = NotificationService()
        await notification_service.notify_scene_analysis_request(
            request_id=request_id,
            char_name=ws_target,
            prompt=analysis_data["prompt"],
            llm_config=analysis_data["llm_config"],
            speakers=req.speakers,
            chat_branch=req.chat_branch,
            trigger_floor=trigger_floor,
            context_fingerprint=req.context_fingerprint,
            context=context_serializable,
            user_name=req.user_name
        )
        
        print(f"[Webhook] âœ… å·²å‘é€åœºæ™¯åˆ†æè¯·æ±‚: request_id={request_id}")
        print(f"[Webhook] â³ ç­‰å¾…å‰ç«¯è°ƒç”¨ LLM åè¿”å›ç»“æœåˆ° /api/scene_analysis/complete")
        
        return {
            "status": "pending_analysis",
            "request_id": request_id,
            "message": f"åœºæ™¯åˆ†æè¯·æ±‚å·²å‘é€ï¼Œç­‰å¾… LLM è¿”å›ç»“æœ"
        }

    except Exception as e:
        print(f"[Webhook] âŒ é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


class SceneAnalysisCompleteRequest(BaseModel):
    """åœºæ™¯åˆ†æå®Œæˆè¯·æ±‚"""
    request_id: str
    llm_response: str
    chat_branch: str
    speakers: List[str]
    trigger_floor: int
    context_fingerprint: str
    context: List[Dict]
    char_name: Optional[str] = None
    user_name: Optional[str] = None


@router.post("/scene_analysis/complete")
async def scene_analysis_complete(req: SceneAnalysisCompleteRequest):
    """
    æ¥æ”¶å‰ç«¯çš„åœºæ™¯åˆ†æ LLM ç»“æœ
    
    å‰ç«¯è°ƒç”¨ LLM å®Œæˆåœºæ™¯åˆ†æåï¼Œå°†ç»“æœå‘é€åˆ°æ­¤ç«¯ç‚¹ã€‚
    åç«¯è§£æç»“æœå¹¶æ ¹æ® suggested_action åˆ†æµåˆ° phone_call æˆ– eavesdropã€‚
    
    Args:
        req: åŒ…å« LLM å“åº”å’ŒåŸå§‹è¯·æ±‚æ•°æ®
        
    Returns:
        åˆ†æµç»“æœ
    """
    try:
        check_phone_call_enabled()
        from services.scene_analyzer import SceneAnalyzer
        from services.auto_call_scheduler import AutoCallScheduler
        from services.eavesdrop_scheduler import EavesdropScheduler
        
        print(f"\n[SceneAnalysisComplete] æ”¶åˆ°åœºæ™¯åˆ†æç»“æœ:")
        print(f"  - request_id: {req.request_id}")
        print(f"  - llm_response é•¿åº¦: {len(req.llm_response)}")
        print(f"  - speakers: {req.speakers}")
        print(f"  - trigger_floor: {req.trigger_floor}")
        
        # è§£æ LLM å“åº”
        analyzer = SceneAnalyzer()
        analysis = analyzer.parse_llm_response(req.llm_response, req.speakers)
        
        suggested_action = analysis.suggested_action
        print(f"[SceneAnalysisComplete] ğŸ“Š åˆ†æç»“æœ: action={suggested_action}, reason={analysis.reason}")
        
        # ==================== æ ¹æ®åˆ†æç»“æœåˆ†æµ ====================
        if suggested_action == "eavesdrop":
            # å¯¹è¯è¿½è¸ªæµç¨‹
            print(f"[SceneAnalysisComplete] ğŸ§ è§¦å‘å¯¹è¯è¿½è¸ª")
            eavesdrop_scheduler = EavesdropScheduler()
            record_id = await eavesdrop_scheduler.schedule_eavesdrop(
                chat_branch=req.chat_branch,
                speakers=req.speakers,
                trigger_floor=req.trigger_floor,
                context=req.context,
                context_fingerprint=req.context_fingerprint,
                user_name=req.user_name,
                char_name=req.char_name,
                scene_description=analysis.scene_description
            )
            
            if record_id is None:
                return {
                    "status": "duplicate",
                    "message": "è¯¥ä¸Šä¸‹æ–‡å·²ç”Ÿæˆæˆ–æ­£åœ¨ç”Ÿæˆä¸­"
                }
            
            return {
                "status": "scheduled",
                "action": "eavesdrop",
                "record_id": record_id,
                "analysis": {
                    "action": suggested_action,
                    "reason": analysis.reason,
                    "characters_present": analysis.characters_present
                },
                "message": f"å·²è°ƒåº¦å¯¹è¯è¿½è¸ªä»»åŠ¡: {req.speakers} @ æ¥¼å±‚{req.trigger_floor}"
            }
            
        elif suggested_action == "phone_call":
            # ä¸»åŠ¨ç”µè¯æµç¨‹
            print(f"[SceneAnalysisComplete] ğŸ“ è§¦å‘ä¸»åŠ¨ç”µè¯")
            scheduler = AutoCallScheduler()
            call_id = await scheduler.schedule_auto_call(
                chat_branch=req.chat_branch,
                speakers=req.speakers,
                trigger_floor=req.trigger_floor,
                context=req.context,
                context_fingerprint=req.context_fingerprint,
                user_name=req.user_name,
                char_name=req.char_name
            )

            if call_id is None:
                return {
                    "status": "duplicate",
                    "message": "è¯¥æ¥¼å±‚å·²ç”Ÿæˆæˆ–æ­£åœ¨ç”Ÿæˆä¸­"
                }

            return {
                "status": "scheduled",
                "action": "phone_call",
                "call_id": call_id,
                "analysis": {
                    "action": suggested_action,
                    "reason": analysis.reason,
                    "character_left": analysis.character_left
                },
                "message": f"å·²è°ƒåº¦è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡: {req.speakers} @ æ¥¼å±‚{req.trigger_floor}"
            }
        
        else:
            # åœºæ™¯åˆ†æå»ºè®®ä¸è§¦å‘
            print(f"[SceneAnalysisComplete] â­ï¸ åœºæ™¯åˆ†æå»ºè®®ä¸è§¦å‘: {analysis.reason}")
            return {
                "status": "skipped",
                "action": "none",
                "analysis": {
                    "action": suggested_action,
                    "reason": analysis.reason
                },
                "message": f"åœºæ™¯åˆ†æå»ºè®®ä¸è§¦å‘: {analysis.reason}"
            }
            
    except Exception as e:
        print(f"[SceneAnalysisComplete] âŒ é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/phone_call/auto/history/{char_name}")
async def get_auto_call_history(char_name: str, limit: int = 50):
    """
    è·å–è§’è‰²çš„è‡ªåŠ¨ç”Ÿæˆå†å²è®°å½•

    Args:
        char_name: è§’è‰²åç§°
        limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶

    Returns:
        å†å²è®°å½•åˆ—è¡¨
    """
    try:
        check_phone_call_enabled()
        from database import DatabaseManager

        db = DatabaseManager()
        history = db.get_auto_call_history(char_name, limit)

        return {
            "status": "success",
            "char_name": char_name,
            "history": history,
            "total": len(history)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/phone_call/auto/history_by_branch/{chat_branch:path}")
async def get_auto_call_history_by_branch(chat_branch: str, limit: int = 50):
    """
    æ ¹æ®å¯¹è¯åˆ†æ”¯è·å–è‡ªåŠ¨ç”Ÿæˆå†å²è®°å½•
    
    Args:
        chat_branch: å¯¹è¯åˆ†æ”¯ID
        limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶
        
    Returns:
        å†å²è®°å½•åˆ—è¡¨
    """
    try:
        check_phone_call_enabled()
        from database import DatabaseManager
        
        db = DatabaseManager()
        history = db.get_auto_call_history_by_chat_branch(chat_branch, limit)
        
        return {
            "status": "success",
            "chat_branch": chat_branch,
            "history": history,
            "total": len(history)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class FingerprintHistoryRequest(BaseModel):
    """æŒ‰æŒ‡çº¹æŸ¥è¯¢å†å²è¯·æ±‚"""
    fingerprints: List[str]
    limit: Optional[int] = 50


@router.post("/phone_call/auto/history_by_fingerprints")
async def get_auto_call_history_by_fingerprints(req: FingerprintHistoryRequest):
    """
    æ ¹æ®æŒ‡çº¹åˆ—è¡¨è·å–è‡ªåŠ¨ç”Ÿæˆå†å²è®°å½•ï¼ˆæ”¯æŒè·¨åˆ†æ”¯åŒ¹é…ï¼‰
    
    Args:
        req: åŒ…å«æŒ‡çº¹åˆ—è¡¨å’Œé™åˆ¶æ•°é‡
        
    Returns:
        å†å²è®°å½•åˆ—è¡¨
    """
    try:
        check_phone_call_enabled()
        from database import DatabaseManager
        
        db = DatabaseManager()
        history = db.get_auto_call_history_by_fingerprints(req.fingerprints, req.limit)
        
        return {
            "status": "success",
            "fingerprints_count": len(req.fingerprints),
            "history": history,
            "total": len(history)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/phone_call/auto/latest/{char_name}")
async def get_latest_auto_call(char_name: str):
    """
    è·å–è§’è‰²æœ€æ–°çš„è‡ªåŠ¨ç”Ÿæˆè®°å½•

    Args:
        char_name: è§’è‰²åç§°

    Returns:
        æœ€æ–°è®°å½•æˆ– null
    """
    try:
        check_phone_call_enabled()
        from database import DatabaseManager

        db = DatabaseManager()
        latest = db.get_latest_auto_call(char_name)

        if latest is None:
            return {
                "status": "success",
                "char_name": char_name,
                "latest": None
            }

        return {
            "status": "success",
            "char_name": char_name,
            "latest": latest
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


from fastapi import WebSocket, WebSocketDisconnect

@router.websocket("/ws/phone_call/{char_name}")
async def websocket_phone_call(websocket: WebSocket, char_name: str):
    """
    WebSocket å®æ—¶æ¨é€è¿æ¥

    å‰ç«¯å»ºç«‹è¿æ¥å,å½“æœ‰æ–°çš„è‡ªåŠ¨ç”Ÿæˆå®Œæˆæ—¶ä¼šæ”¶åˆ°æ¨é€

    Args:
        websocket: WebSocket è¿æ¥
        char_name: è§’è‰²åç§°
    """
    from services.notification_service import NotificationService

    await websocket.accept()
    await NotificationService.register_connection(char_name, websocket)

    try:
        print(f"[WebSocket] è¿æ¥å·²å»ºç«‹: {char_name}")

        # å‘é€æ¬¢è¿æ¶ˆæ¯
        await websocket.send_json({
            "type": "connected",
            "char_name": char_name,
            "message": "WebSocket è¿æ¥å·²å»ºç«‹"
        })

        # ä¿æŒè¿æ¥,æ¥æ”¶å¿ƒè·³
        while True:
            data = await websocket.receive_text()

            # å¤„ç†å¿ƒè·³
            if data == "ping":
                await websocket.send_text("pong")

    except WebSocketDisconnect:
        print(f"[WebSocket] è¿æ¥å·²æ–­å¼€: {char_name}")
    except Exception as e:
        print(f"[WebSocket] é”™è¯¯: {char_name}, {str(e)}")
    finally:
        await NotificationService.unregister_connection(char_name, websocket)


# ==================== æµ‹è¯•æ¥å£ ====================

class TestTriggerRequest(BaseModel):
    """æµ‹è¯•è§¦å‘è¯·æ±‚"""
    speakers: List[str]  # è¯´è¯äººåˆ—è¡¨
    trigger_floor: int  # è§¦å‘æ¥¼å±‚
    chat_branch: Optional[str] = "test_branch"  # å¯¹è¯åˆ†æ”¯ID,é»˜è®¤ä¸ºæµ‹è¯•åˆ†æ”¯
    context_count: Optional[int] = 30  # ä»å½“å‰å¯¹è¯ä¸­æå–çš„ä¸Šä¸‹æ–‡æ•°é‡


@router.post("/phone_call/test/trigger_auto_call")
async def test_trigger_auto_call(req: TestTriggerRequest):
    """
    æµ‹è¯•æ¥å£: æ‰‹åŠ¨è§¦å‘è‡ªåŠ¨ç”µè¯ç”Ÿæˆ

    ç”¨äºå¼€å‘æµ‹è¯•,ç›´æ¥è§¦å‘è‡ªåŠ¨è°ƒåº¦,æ— éœ€ç­‰å¾… webhook

    Args:
        req: åŒ…å«è¯´è¯äººåˆ—è¡¨ã€è§¦å‘æ¥¼å±‚ç­‰ä¿¡æ¯

    Returns:
        è°ƒåº¦ç»“æœ
    """
    try:
        check_phone_call_enabled()
        from services.auto_call_scheduler import AutoCallScheduler
        from services.conversation_monitor import ConversationMonitor

        print(f"\n[TestTrigger] æ‰‹åŠ¨è§¦å‘æµ‹è¯•:")
        print(f"  - speakers: {req.speakers}")
        print(f"  - trigger_floor: {req.trigger_floor}")
        print(f"  - chat_branch: {req.chat_branch}")
        print(f"  - context_count: {req.context_count}")

        # ä» SillyTavern è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡
        # æ³¨æ„: è¿™é‡Œéœ€è¦å‰ç«¯ä¼ é€’ä¸Šä¸‹æ–‡,å› ä¸ºåç«¯æ— æ³•ç›´æ¥è®¿é—® SillyTavern çš„å¯¹è¯æ•°æ®
        # æ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿä¸Šä¸‹æ–‡
        monitor = ConversationMonitor()

        # æ¨¡æ‹Ÿä¸Šä¸‹æ–‡ (å®é™…ä½¿ç”¨æ—¶,å‰ç«¯åº”è¯¥ä¼ é€’çœŸå®çš„å¯¹è¯ä¸Šä¸‹æ–‡)
        context = [
            {"name": "User", "is_user": True, "mes": "ä½ å¥½"},
            {"name": req.speakers[0] if req.speakers else "è§’è‰²", "is_user": False, "mes": "ä½ å¥½!æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—?"}
        ]

        # è°ƒåº¦ç”Ÿæˆä»»åŠ¡
        scheduler = AutoCallScheduler()
        call_id = await scheduler.schedule_auto_call(
            chat_branch=req.chat_branch,
            speakers=req.speakers,
            trigger_floor=req.trigger_floor,
            context=context
        )

        if call_id is None:
            return {
                "status": "duplicate",
                "message": f"è¯¥æ¥¼å±‚å·²ç”Ÿæˆæˆ–æ­£åœ¨ç”Ÿæˆä¸­: æ¥¼å±‚{req.trigger_floor}"
            }

        return {
            "status": "success",
            "call_id": call_id,
            "message": f"âœ… æµ‹è¯•è§¦å‘æˆåŠŸ: call_id={call_id}, speakers={req.speakers} @ æ¥¼å±‚{req.trigger_floor}"
        }

    except Exception as e:
        print(f"[TestTrigger] âŒ é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


class ErrorLogRequest(BaseModel):
    """å‰ç«¯é”™è¯¯æ—¥å¿—è¯·æ±‚"""
    error_type: str
    error_message: str
    error_stack: Optional[str] = None
    call_id: Optional[int] = None
    char_name: Optional[str] = None
    llm_config: Optional[Dict] = None
    raw_llm_response: Optional[Dict] = None  # åŸå§‹LLMå“åº”æ•°æ®
    timestamp: str


@router.post("/phone_call/log_error")
async def log_error(req: ErrorLogRequest):
    """
    æ¥æ”¶å‰ç«¯é”™è¯¯æ—¥å¿—å¹¶è¾“å‡ºåˆ°åç«¯æ§åˆ¶å°

    Args:
        req: é”™è¯¯æ—¥å¿—ä¿¡æ¯

    Returns:
        ç¡®è®¤ä¿¡æ¯
    """
    print(f"\n{'='*80}")
    print(f"[å‰ç«¯é”™è¯¯æŠ¥å‘Š] {req.timestamp}")
    print(f"{'='*80}")
    print(f"é”™è¯¯ç±»å‹: {req.error_type}")
    print(f"é”™è¯¯æ¶ˆæ¯: {req.error_message}")

    if req.call_id:
        print(f"Call ID: {req.call_id}")

    if req.char_name:
        print(f"è§’è‰²åç§°: {req.char_name}")

    if req.llm_config:
        print(f"\nLLM é…ç½®:")
        print(f"  - API URL: {req.llm_config.get('api_url', 'N/A')}")
        print(f"  - Model: {req.llm_config.get('model', 'N/A')}")
        print(f"  - Temperature: {req.llm_config.get('temperature', 'N/A')}")
        print(f"  - Max Tokens: {req.llm_config.get('max_tokens', 'N/A')}")

    if req.raw_llm_response:
        import json
        print(f"\nåŸå§‹ LLM å“åº”æ•°æ®:")
        print(f"  - æ•°æ®ç±»å‹: {type(req.raw_llm_response).__name__}")
        if isinstance(req.raw_llm_response, dict):
            print(f"  - å“åº”é”®: {list(req.raw_llm_response.keys())}")
        print(f"\nå®Œæ•´å“åº” (JSONæ ¼å¼):")
        print(json.dumps(req.raw_llm_response, indent=2, ensure_ascii=False))

    if req.error_stack:
        print(f"\né”™è¯¯å †æ ˆ:")
        print(req.error_stack)

    print(f"{'='*80}\n")

    return {
        "status": "logged",
        "message": "é”™è¯¯å·²è®°å½•åˆ°åç«¯æ§åˆ¶å°"
    }
