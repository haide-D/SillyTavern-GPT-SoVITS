"""
å¯¹è¯è¿½è¸ªæœåŠ¡

ç”¨äºç”Ÿæˆå¤šäººç§ä¸‹å¯¹è¯å†…å®¹
"""
import os
import random
from typing import List, Dict, Optional
from config import load_json, SETTINGS_FILE, get_current_dirs, get_sovits_host
from services.llm_service import LLMService
from services.emotion_service import EmotionService
from phone_call_utils.prompt_builder import PromptBuilder
from phone_call_utils.response_parser import ResponseParser
from phone_call_utils.models import MultiSpeakerSegment, EavesdropResult
from phone_call_utils.tts_service import TTSService
from phone_call_utils.audio_merger import AudioMerger
from utils import scan_audio_files


class EavesdropService:
    """å¯¹è¯è¿½è¸ªæœåŠ¡ - ç”Ÿæˆå¤šäººç§ä¸‹å¯¹è¯"""
    
    def __init__(self):
        self.llm_service = LLMService()
        self.emotion_service = EmotionService()
        self.prompt_builder = PromptBuilder()
        self.response_parser = ResponseParser()
        self.tts_service = TTSService(get_sovits_host())
        self.audio_merger = AudioMerger()
    
    async def build_prompt(
        self,
        context: List[Dict],
        speakers: List[str],
        user_name: str = "ç”¨æˆ·",
        text_lang: str = "zh",
        max_context_messages: int = 20,
        scene_description: str = None,
        eavesdrop_config: Dict = None  # åˆ†æ LLM æä¾›çš„å¯¹è¯ä¸»é¢˜å’Œæ¡†æ¶
    ) -> Dict:
        """
        æ„å»ºå¯¹è¯è¿½è¸ª Prompt
        
        Args:
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            speakers: å‚ä¸è§’è‰²åˆ—è¡¨ï¼ˆåœ¨åœºè§’è‰²ï¼‰
            user_name: ç”¨æˆ·å
            text_lang: æ–‡æœ¬è¯­è¨€
            max_context_messages: æœ€å¤§ä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°
            scene_description: åœºæ™¯æè¿°ï¼ˆå¯é€‰ï¼‰
            eavesdrop_config: åˆ†æ LLM æä¾›çš„å¯¹è¯ä¸»é¢˜ã€æ¡†æ¶ç­‰é…ç½®
            
        Returns:
            åŒ…å« promptã€speakers_emotions ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        print(f"[EavesdropService] æ„å»º Prompt: speakers={speakers}, text_lang={text_lang}")
        
        if eavesdrop_config:
            print(f"[EavesdropService] ğŸ­ ä½¿ç”¨åˆ†æ LLM æä¾›çš„é…ç½®:")
            print(f"  - å¯¹è¯ä¸»é¢˜: {eavesdrop_config.get('conversation_theme', 'æœªæŒ‡å®š')}")
            print(f"  - æˆå‰§å¼ åŠ›: {eavesdrop_config.get('dramatic_tension', 'æœªæŒ‡å®š')}")
        
        # è·å–æ‰€æœ‰è¯´è¯äººçš„å¯ç”¨æƒ…ç»ª
        speakers_emotions = {}
        valid_speakers = []
        
        for speaker in speakers:
            try:
                emotions = self.emotion_service.get_available_emotions(speaker)
                speakers_emotions[speaker] = emotions
                valid_speakers.append(speaker)
                print(f"[EavesdropService] {speaker} å¯ç”¨æƒ…ç»ª: {emotions}")
            except Exception as e:
                print(f"[EavesdropService] âš ï¸ è·³è¿‡è§’è‰² {speaker}: {e}")
        
        if len(valid_speakers) < 2:
            raise ValueError(f"éœ€è¦è‡³å°‘2ä¸ªæœ‰æ•ˆè§’è‰²è¿›è¡Œå¯¹è¯è¿½è¸ª,å½“å‰åªæœ‰ {len(valid_speakers)} ä¸ª")
        
        # æ„å»º Promptï¼ˆä½¿ç”¨åˆ†æ LLM æä¾›çš„é…ç½®ï¼‰
        prompt = self.prompt_builder.build_eavesdrop_prompt(
            context=context,
            speakers_emotions=speakers_emotions,
            user_name=user_name,
            text_lang=text_lang,
            max_context_messages=max_context_messages,
            eavesdrop_config=eavesdrop_config  # âœ… ä¼ é€’å¯¹è¯ä¸»é¢˜å’Œæ¡†æ¶
        )
        
        # è¯»å– LLM é…ç½®
        settings = load_json(SETTINGS_FILE)
        phone_call_config = settings.get("phone_call", {})
        llm_config = phone_call_config.get("llm", {})
        
        print(f"[EavesdropService] âœ… Prompt æ„å»ºå®Œæˆ: {len(prompt)} å­—ç¬¦")
        
        return {
            "prompt": prompt,
            "speakers": valid_speakers,
            "speakers_emotions": speakers_emotions,
            "text_lang": text_lang,
            "llm_config": {
                "api_url": llm_config.get("api_url"),
                "api_key": llm_config.get("api_key"),
                "model": llm_config.get("model"),
                "temperature": llm_config.get("temperature", 0.8),
                "max_tokens": llm_config.get("max_tokens", 5000)
            },
            "message": "è¯·ä½¿ç”¨å‰ç«¯ LLM è°ƒç”¨æ­¤ Prompt,ç„¶åå°†å“åº”å‘é€åˆ° /api/eavesdrop/complete_generation"
        }
    
    async def complete_generation(
        self,
        llm_response: str,
        speakers_emotions: Dict[str, List[str]],
        text_lang: str = "zh"
    ) -> Dict:
        """
        å®Œæˆå¯¹è¯è¿½è¸ªç”Ÿæˆï¼ˆè§£æ LLM å“åº”å¹¶ç”ŸæˆéŸ³é¢‘ï¼‰
        
        Args:
            llm_response: LLM è¿”å›çš„å“åº”
            speakers_emotions: è¯´è¯äººæƒ…ç»ªæ˜ å°„
            text_lang: æ–‡æœ¬è¯­è¨€
            
        Returns:
            åŒ…å« segmentsã€audio_url ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        print(f"[EavesdropService] å¼€å§‹è§£æå“åº”å¹¶ç”ŸæˆéŸ³é¢‘")
        
        # 1. è§£æå“åº”
        segments = self.response_parser.parse_multi_speaker_response(
            response=llm_response,
            speakers_emotions=speakers_emotions
        )
        
        if not segments:
            raise ValueError("æœªèƒ½è§£æå‡ºä»»ä½•å¯¹è¯ç‰‡æ®µ")
        
        print(f"[EavesdropService] è§£æåˆ° {len(segments)} ä¸ªå¯¹è¯ç‰‡æ®µ")
        
        # è¯»å– TTS é…ç½®
        settings = load_json(SETTINGS_FILE)
        tts_config = settings.get("phone_call", {}).get("tts_config", {})
        
        # 2. ä¸ºæ¯ä¸ªç‰‡æ®µç”Ÿæˆ TTS éŸ³é¢‘
        audio_bytes_list = []
        previous_ref_audio = None
        
        for i, seg in enumerate(segments):
            try:
                # é€‰æ‹©å‚è€ƒéŸ³é¢‘
                ref_audio = self._select_ref_audio(seg.speaker, seg.emotion)
                if not ref_audio:
                    print(f"[EavesdropService] âš ï¸ è·³è¿‡ç‰‡æ®µ {i}: æ— å‚è€ƒéŸ³é¢‘")
                    continue
                
                # å°† MultiSpeakerSegment è½¬æ¢ä¸º EmotionSegment æ ¼å¼
                from phone_call_utils.response_parser import EmotionSegment
                emotion_segment = EmotionSegment(
                    emotion=seg.emotion,
                    text=seg.text,
                    speed=seg.speed
                )
                
                # ç”Ÿæˆ TTS (ä½¿ç”¨æ­£ç¡®çš„ generate_audio æ–¹æ³•)
                audio_bytes = await self.tts_service.generate_audio(
                    segment=emotion_segment,
                    ref_audio=ref_audio,
                    tts_config=tts_config,
                    previous_ref_audio=previous_ref_audio
                )
                
                audio_bytes_list.append(audio_bytes)
                previous_ref_audio = ref_audio  # ä¿å­˜ç”¨äºä¸‹ä¸€ä¸ªæƒ…ç»ªè¿‡æ¸¡
                
                # æ›´æ–° segment çš„éŸ³é¢‘æ—¶é•¿
                # (ç®€åŒ–å¤„ç†,å®é™…åº”è¯¥è§£æéŸ³é¢‘è·å–æ—¶é•¿)
                
            except Exception as e:
                print(f"[EavesdropService] âš ï¸ ç”Ÿæˆç‰‡æ®µ {i} TTS å¤±è´¥: {e}")
                continue

        
        if not audio_bytes_list:
            raise ValueError("æ‰€æœ‰ç‰‡æ®µçš„ TTS ç”Ÿæˆéƒ½å¤±è´¥äº†")
        
        # 3. åˆå¹¶éŸ³é¢‘
        settings = load_json(SETTINGS_FILE)
        phone_call_config = settings.get("phone_call", {})
        audio_merger_config = phone_call_config.get("audio_merge", {})
        
        # æ·»åŠ å¤šè¯´è¯äººåˆå¹¶é…ç½®
        audio_merger_config["speaker_change_pause"] = audio_merger_config.get("speaker_change_pause", 0.6)
        audio_merger_config["same_speaker_pause"] = audio_merger_config.get("same_speaker_pause", 0.3)
        
        merged_audio = self.audio_merger.merge_multi_speaker_segments(
            segments=segments[:len(audio_bytes_list)],  # åªå–æˆåŠŸç”ŸæˆéŸ³é¢‘çš„ç‰‡æ®µ
            audio_bytes_list=audio_bytes_list,
            config=audio_merger_config
        )
        
        print(f"[EavesdropService] âœ… éŸ³é¢‘åˆå¹¶å®Œæˆ: {len(merged_audio)} bytes")
        
        # 4. ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        import time
        timestamp = int(time.time())
        filename = f"eavesdrop_{timestamp}.wav"
        
        cache_dir = os.path.join(os.path.dirname(SETTINGS_FILE), "Cache", "eavesdrop")
        os.makedirs(cache_dir, exist_ok=True)
        
        audio_path = os.path.join(cache_dir, filename)
        with open(audio_path, "wb") as f:
            f.write(merged_audio)
        
        print(f"[EavesdropService] âœ… éŸ³é¢‘ä¿å­˜åˆ°: {audio_path}")
        
        # 5. è¿”å›ç»“æœ
        return {
            "segments": [seg.model_dump() for seg in segments[:len(audio_bytes_list)]],
            "audio_path": audio_path,
            "audio_url": f"/api/audio/eavesdrop/{filename}",
            "segment_count": len(audio_bytes_list)
        }
    
    def _select_ref_audio(self, char_name: str, emotion: str) -> Optional[Dict]:
        """æ ¹æ®æƒ…ç»ªé€‰æ‹©å‚è€ƒéŸ³é¢‘"""
        mappings = load_json(os.path.join(os.path.dirname(SETTINGS_FILE), "character_mappings.json"))
        
        if char_name not in mappings:
            print(f"[EavesdropService] é”™è¯¯: è§’è‰² {char_name} æœªç»‘å®šæ¨¡å‹")
            return None
        
        model_folder = mappings[char_name]
        base_dir, _ = get_current_dirs()
        
        # ä» tts_config.prompt_lang è¯»å–è¯­è¨€è®¾ç½®å¹¶è½¬æ¢ä¸ºç›®å½•å
        settings = load_json(SETTINGS_FILE)
        prompt_lang = settings.get("phone_call", {}).get("tts_config", {}).get("prompt_lang", "zh")
        
        # è¯­è¨€ä»£ç è½¬ç›®å½•åæ˜ å°„
        lang_map = {
            "zh": "Chinese",
            "en": "English",
            "ja": "Japanese",
            "all_zh": "Chinese",
            "all_ja": "Japanese"
        }
        lang_dir = lang_map.get(prompt_lang, "Chinese")
        
        # ä½¿ç”¨é…ç½®çš„è¯­è¨€ç›®å½• + emotions å­ç›®å½•
        ref_dir = os.path.join(base_dir, model_folder, "reference_audios", lang_dir, "emotions")
        
        if not os.path.exists(ref_dir):
            print(f"[EavesdropService] é”™è¯¯: å‚è€ƒéŸ³é¢‘ç›®å½•ä¸å­˜åœ¨: {ref_dir}")
            return None
        
        audio_files = scan_audio_files(ref_dir)
        matching_audios = [a for a in audio_files if a["emotion"] == emotion]
        
        if not matching_audios:
            # å°è¯•ä½¿ç”¨ default ä½œä¸ºåå¤‡
            matching_audios = [a for a in audio_files if a["emotion"] == "default"]
        
        if not matching_audios:
            # å¦‚æœè¿˜æ²¡æœ‰ï¼Œéšæœºé€‰ä¸€ä¸ª
            if audio_files:
                print(f"[EavesdropService] è­¦å‘Š: æœªæ‰¾åˆ°æƒ…ç»ª '{emotion}'ï¼Œä½¿ç”¨éšæœºå‚è€ƒéŸ³é¢‘")
                matching_audios = audio_files
        
        if not matching_audios:
            print(f"[EavesdropService] è­¦å‘Š: æœªæ‰¾åˆ°æƒ…ç»ª '{emotion}' çš„å‚è€ƒéŸ³é¢‘")
            return None
        
        selected = random.choice(matching_audios)
        return {
            "path": selected["path"],
            "text": selected["text"]
        }

