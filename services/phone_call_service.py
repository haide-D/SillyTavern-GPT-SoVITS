import os
import random
from typing import List, Dict
from config import load_json, SETTINGS_FILE, get_current_dirs, get_sovits_host
from services.llm_service import LLMService
from services.emotion_service import EmotionService
from st_utils.data_extractor import DataExtractor
from phone_call_utils.prompt_builder import PromptBuilder
from phone_call_utils.response_parser import ResponseParser, EmotionSegment
from phone_call_utils.tts_service import TTSService
from phone_call_utils.audio_merger import AudioMerger
from utils import scan_audio_files


class PhoneCallService:
    """ä¸»åŠ¨ç”µè¯ç”ŸæˆæœåŠ¡"""
    
    def __init__(self):
        self.llm_service = LLMService()
        self.emotion_service = EmotionService()
        self.data_extractor = DataExtractor()
        self.prompt_builder = PromptBuilder()
        self.response_parser = ResponseParser()
        self.tts_service = TTSService(get_sovits_host())
        self.audio_merger = AudioMerger()
    
    async def generate(self, chat_branch: str, speakers: List[str], context: List[Dict], generate_audio: bool = True, user_name: str = None, last_call_info: Dict = None, call_reason: str = "", call_tone: str = "") -> Dict:
        """
        ç”Ÿæˆä¸»åŠ¨ç”µè¯å†…å®¹
        
        âš ï¸ æ³¨æ„: æ­¤æ–¹æ³•ä¸å†ç›´æ¥è°ƒç”¨LLM!
        æµç¨‹å·²æ”¹ä¸º:
        1. åç«¯æ„å»ºprompt â†’ è¿”å›ç»™å‰ç«¯
        2. å‰ç«¯è°ƒç”¨LLM (ä½¿ç”¨ LLM_Client.callLLM)
        3. å‰ç«¯å°†LLMå“åº”å‘å›åç«¯
        4. åç«¯è§£æå¹¶ç”ŸæˆéŸ³é¢‘
        
        Args:
            chat_branch: å¯¹è¯åˆ†æ”¯ID
            speakers: è¯´è¯äººåˆ—è¡¨
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            generate_audio: æ˜¯å¦ç”ŸæˆéŸ³é¢‘(é»˜è®¤True)
            user_name: ç”¨æˆ·åï¼Œç”¨äºåœ¨promptä¸­åŒºåˆ†ç”¨æˆ·èº«ä»½
            last_call_info: ä¸Šæ¬¡é€šè¯ä¿¡æ¯ï¼Œç”¨äºäºŒæ¬¡ç”µè¯å·®å¼‚åŒ–
            call_reason: æ‰“ç”µè¯çš„åŸå› ï¼ˆç”± LLM åˆ†æå¾—å‡ºï¼‰
            call_tone: é€šè¯æ°›å›´ï¼ˆå¦‚è½»æ¾é—²èŠã€æ·±æƒ…å€¾è¯‰ç­‰ï¼‰
            
        Returns:
            åŒ…å«promptã€llm_configçš„å­—å…¸
        """
        print(f"\n[PhoneCallService] å¼€å§‹å‡†å¤‡ä¸»åŠ¨ç”µè¯: chat_branch={chat_branch}, speakers={speakers}, ä¸Šä¸‹æ–‡={len(context)}æ¡æ¶ˆæ¯")
        if last_call_info:
            print(f"[PhoneCallService] ğŸ“ æ£€æµ‹åˆ°ä¸Šæ¬¡é€šè¯ï¼Œå°†ç”ŸæˆäºŒæ¬¡ç”µè¯å†…å®¹")
        
        # 1. åŠ è½½é…ç½®
        settings = load_json(SETTINGS_FILE)
        phone_call_config = settings.get("phone_call", {})
        
        llm_config = phone_call_config.get("llm", {})
        extractors = phone_call_config.get("data_extractors", [])
        prompt_template = phone_call_config.get("prompt_template", "")
        tts_config = phone_call_config.get("tts_config", {})
        text_lang = tts_config.get("text_lang", "zh")  # è¯»å–è¯­è¨€é…ç½®,é»˜è®¤ä¸­æ–‡
        
        # è¯»å–æ¶ˆæ¯æå–å’Œè¿‡æ»¤é…ç½®ï¼ˆä»å…±äº«çš„ message_processing è¯»å–ï¼‰
        msg_processing = settings.get("message_processing", {})
        extract_tag = msg_processing.get("extract_tag", "")  # æå–æ ‡ç­¾
        filter_tags = msg_processing.get("filter_tags", "")  # è¿‡æ»¤æ ‡ç­¾
        
        # 2. æå–ä¸Šä¸‹æ–‡æ•°æ®
        extracted_data = self.data_extractor.extract(context, extractors)
        
        # 3. è·å–æ‰€æœ‰è¯´è¯äººçš„å¯ç”¨æƒ…ç»ª (è·³è¿‡æœªç»‘å®šæ¨¡å‹çš„è§’è‰²)
        speakers_emotions = {}
        valid_speakers = []
        for speaker in speakers:
            try:
                emotions = self.emotion_service.get_available_emotions(speaker)
                speakers_emotions[speaker] = emotions
                valid_speakers.append(speaker)
                print(f"[PhoneCallService] {speaker} å¯ç”¨æƒ…ç»ª: {emotions}")
            except Exception as e:
                print(f"[PhoneCallService] âš ï¸ è·³è¿‡è§’è‰² {speaker}: {e}")
        
        # å¦‚æœæ‰€æœ‰è§’è‰²éƒ½æœªç»‘å®šï¼Œç»ˆæ­¢
        if not valid_speakers:
            from fastapi import HTTPException
            raise HTTPException(status_code=400, detail="æ‰€æœ‰è§’è‰²éƒ½æœªç»‘å®šæ¨¡å‹ï¼Œæ— æ³•ç”Ÿæˆç”µè¯")
        
        # æ›´æ–°speakersä¸ºæœ‰æ•ˆçš„è¯´è¯äººåˆ—è¡¨
        speakers = valid_speakers
        
        # 4. æ„å»ºæç¤ºè¯ (åŒ…å«è¯´è¯äººå’Œæƒ…ç»ªä¿¡æ¯ï¼Œä»¥åŠä¸Šæ¬¡é€šè¯ä¿¡æ¯)
        prompt = self.prompt_builder.build(
            template=prompt_template,
            char_name=speakers[0] if speakers else "Unknown",
            context=context,
            extracted_data=extracted_data,
            emotions=speakers_emotions.get(speakers[0], []) if speakers else [],
            speakers=speakers,
            speakers_emotions=speakers_emotions,
            text_lang=text_lang,
            extract_tag=extract_tag,
            filter_tags=filter_tags,
            user_name=user_name,
            last_call_info=last_call_info,
            call_reason=call_reason,  # æ–°å¢: ç”µè¯åŸå› 
            call_tone=call_tone  # æ–°å¢: é€šè¯æ°›å›´
        )
        
        print(f"[PhoneCallService] âœ… Promptæ„å»ºå®Œæˆ: {len(prompt)} å­—ç¬¦")
        print(f"[PhoneCallService] âš ï¸ ä¸å†è°ƒç”¨LLM - è¯·å‰ç«¯ä½¿ç”¨ LLM_Client.callLLM()")
        
        # æ‰“å°å®Œæ•´çš„ LLM è¯·æ±‚ä½“ (JSON æ ¼å¼,æ–¹ä¾¿æµ‹è¯•)
        import json
        llm_request_body = {
            "model": llm_config.get("model"),
            "messages": [{"role": "user", "content": prompt}],
            "temperature": llm_config.get("temperature", 0.8),
            "max_tokens": llm_config.get("max_tokens"),
            "stream": False
        }
        
        print(f"\n{'='*80}")
        print(f"[PhoneCallService] å®Œæ•´ LLM è¯·æ±‚ä½“ (JSON æ ¼å¼):")
        print(f"{'='*80}")
        print(json.dumps(llm_request_body, indent=2, ensure_ascii=False))
        print(f"{'='*80}\n")
        
        # è¿”å›promptå’Œé…ç½®,ä¾›å‰ç«¯è°ƒç”¨LLM
        return {
            "prompt": prompt,
            "llm_config": llm_config,
            "speakers": speakers,
            "speakers_emotions": speakers_emotions,
            "message": "è¯·ä½¿ç”¨å‰ç«¯ LLM_Client.callLLM() è°ƒç”¨LLM,ç„¶åå°†å“åº”å‘é€åˆ° /api/phone_call/parse_and_generate"
        }
    
    def _select_ref_audio(self, char_name: str, emotion: str) -> Dict:
        """
        æ ¹æ®æƒ…ç»ªé€‰æ‹©å‚è€ƒéŸ³é¢‘
        
        Args:
            char_name: è§’è‰²åç§°
            emotion: æƒ…ç»ªåç§°
            
        Returns:
            å‚è€ƒéŸ³é¢‘ä¿¡æ¯ {path, text} æˆ– None
        """
        # è·å–è§’è‰²æ¨¡å‹æ–‡ä»¶å¤¹
        mappings = load_json(os.path.join(os.path.dirname(SETTINGS_FILE), "character_mappings.json"))
        
        if char_name not in mappings:
            print(f"[PhoneCallService] é”™è¯¯: è§’è‰² {char_name} æœªç»‘å®šæ¨¡å‹")
            return None
        
        model_folder = mappings[char_name]
        base_dir, _ = get_current_dirs()
        ref_dir = os.path.join(base_dir, model_folder, "reference_audios")
        
        if not os.path.exists(ref_dir):
            print(f"[PhoneCallService] é”™è¯¯: å‚è€ƒéŸ³é¢‘ç›®å½•ä¸å­˜åœ¨: {ref_dir}")
            return None
        
        # æ‰«æéŸ³é¢‘æ–‡ä»¶
        audio_files = scan_audio_files(ref_dir)
        
        # ç­›é€‰åŒ¹é…æƒ…ç»ªçš„éŸ³é¢‘
        matching_audios = [a for a in audio_files if a["emotion"] == emotion]
        
        if not matching_audios:
            print(f"[PhoneCallService] è­¦å‘Š: æœªæ‰¾åˆ°æƒ…ç»ª '{emotion}' çš„å‚è€ƒéŸ³é¢‘")
            return None
        
        # éšæœºé€‰æ‹©ä¸€ä¸ª
        selected = random.choice(matching_audios)
        
        return {
            "path": selected["path"],
            "text": selected["text"]
        }
